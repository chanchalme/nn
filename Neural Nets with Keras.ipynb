{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: pip in /anaconda3/lib/python3.6/site-packages (20.2.3)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Using cached tensorflow-2.3.1-cp36-cp36m-macosx_10_9_x86_64.whl (165.1 MB)\n",
      "Collecting keras-preprocessing<1.2,>=1.1.1\n",
      "  Using cached Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "Collecting numpy<1.19.0,>=1.16.0\n",
      "  Using cached numpy-1.18.5-cp36-cp36m-macosx_10_9_x86_64.whl (15.1 MB)\n",
      "Requirement already satisfied, skipping upgrade: termcolor>=1.1.0 in /anaconda3/lib/python3.6/site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.12.0 in /anaconda3/lib/python3.6/site-packages (from tensorflow) (1.15.0)\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Using cached opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Requirement already satisfied, skipping upgrade: protobuf>=3.9.2 in /anaconda3/lib/python3.6/site-packages (from tensorflow) (3.13.0)\n",
      "Collecting gast==0.3.3\n",
      "  Using cached gast-0.3.3-py2.py3-none-any.whl (9.7 kB)\n",
      "Requirement already satisfied, skipping upgrade: google-pasta>=0.1.8 in /anaconda3/lib/python3.6/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied, skipping upgrade: absl-py>=0.7.0 in /anaconda3/lib/python3.6/site-packages (from tensorflow) (0.10.0)\n",
      "Collecting h5py<2.11.0,>=2.10.0\n",
      "  Using cached h5py-2.10.0-cp36-cp36m-macosx_10_6_intel.whl (3.0 MB)\n",
      "Collecting tensorboard<3,>=2.3.0\n",
      "  Using cached tensorboard-2.3.0-py3-none-any.whl (6.8 MB)\n",
      "Requirement already satisfied, skipping upgrade: astunparse==1.6.3 in /anaconda3/lib/python3.6/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied, skipping upgrade: tensorflow-estimator<2.4.0,>=2.3.0 in /anaconda3/lib/python3.6/site-packages (from tensorflow) (2.3.0)\n",
      "Requirement already satisfied, skipping upgrade: wrapt>=1.11.1 in /anaconda3/lib/python3.6/site-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied, skipping upgrade: wheel>=0.26 in /anaconda3/lib/python3.6/site-packages (from tensorflow) (0.32.3)\n",
      "Requirement already satisfied, skipping upgrade: grpcio>=1.8.6 in /anaconda3/lib/python3.6/site-packages (from tensorflow) (1.13.0)\n",
      "Requirement already satisfied, skipping upgrade: setuptools in /anaconda3/lib/python3.6/site-packages (from protobuf>=3.9.2->tensorflow) (36.5.0.post20170921)\n",
      "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /anaconda3/lib/python3.6/site-packages (from tensorboard<3,>=2.3.0->tensorflow) (3.0.1)\n",
      "Requirement already satisfied, skipping upgrade: requests<3,>=2.21.0 in /anaconda3/lib/python3.6/site-packages (from tensorboard<3,>=2.3.0->tensorflow) (2.24.0)\n",
      "Collecting google-auth<2,>=1.6.3\n",
      "  Using cached google_auth-1.22.1-py2.py3-none-any.whl (114 kB)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Using cached google_auth_oauthlib-0.4.1-py2.py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /anaconda3/lib/python3.6/site-packages (from tensorboard<3,>=2.3.0->tensorflow) (0.12.2)\n",
      "Requirement already satisfied, skipping upgrade: tensorboard-plugin-wit>=1.6.0 in /anaconda3/lib/python3.6/site-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.7.0)\n",
      "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /anaconda3/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (1.22)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /anaconda3/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (2020.6.20)\n",
      "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /anaconda3/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /anaconda3/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (2.6)\n",
      "Requirement already satisfied, skipping upgrade: rsa<5,>=3.1.4; python_version >= \"3.5\" in /anaconda3/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (3.4.2)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Using cached pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "Collecting cachetools<5.0,>=2.0.0\n",
      "  Using cached cachetools-4.1.1-py3-none-any.whl (10 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Using cached requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied, skipping upgrade: pyasn1>=0.1.3 in /anaconda3/lib/python3.6/site-packages (from rsa<5,>=3.1.4; python_version >= \"3.5\"->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (0.4.4)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Using cached oauthlib-3.1.0-py2.py3-none-any.whl (147 kB)\n",
      "Installing collected packages: numpy, keras-preprocessing, opt-einsum, gast, h5py, pyasn1-modules, cachetools, google-auth, oauthlib, requests-oauthlib, google-auth-oauthlib, tensorboard, tensorflow\n",
      "\u001b[33m  WARNING: The scripts f2py, f2py3 and f2py3.6 are installed in '/Users/cmeena/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "\u001b[33m  WARNING: The script google-oauthlib-tool is installed in '/Users/cmeena/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "\u001b[33m  WARNING: The script tensorboard is installed in '/Users/cmeena/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "\u001b[33m  WARNING: The scripts estimator_ckpt_converter, saved_model_cli, tensorboard, tf_upgrade_v2, tflite_convert, toco and toco_from_protos are installed in '/Users/cmeena/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "\u001b[31mERROR: After October 2020 you may experience errors when installing or updating packages. This is because pip will change the way that it resolves dependency conflicts.\n",
      "\n",
      "We recommend you use --use-feature=2020-resolver to test your packages with the new resolver before it becomes the default.\n",
      "\n",
      "thinc 6.12.0 requires wrapt<1.11.0,>=1.10.0, but you'll have wrapt 1.12.1 which is incompatible.\n",
      "tensorboard 2.3.0 requires grpcio>=1.24.3, but you'll have grpcio 1.13.0 which is incompatible.\n",
      "tensorboard 2.3.0 requires setuptools>=41.0.0, but you'll have setuptools 36.5.0.post20170921 which is incompatible.\n",
      "spacy 2.0.16 requires regex==2018.01.10, but you'll have regex 2018.11.22 which is incompatible.\n",
      "pyasn1-modules 0.2.8 requires pyasn1<0.5.0,>=0.4.6, but you'll have pyasn1 0.4.4 which is incompatible.\n",
      "google-auth 1.22.1 requires setuptools>=40.3.0, but you'll have setuptools 36.5.0.post20170921 which is incompatible.\u001b[0m\n",
      "Successfully installed cachetools-4.1.1 gast-0.3.3 google-auth-1.22.1 google-auth-oauthlib-0.4.1 h5py-2.10.0 keras-preprocessing-1.1.2 numpy-1.18.5 oauthlib-3.1.0 opt-einsum-3.3.0 pyasn1-modules-0.2.8 requests-oauthlib-1.3.0 tensorboard-2.3.0 tensorflow-2.3.1\n"
     ]
    }
   ],
   "source": [
    "!pip install --user --upgrade tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.1\n",
      "2.4.0\n",
      "2.3.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import tensorboard\n",
    "print(tf.__version__)\n",
    "print(keras.__version__)\n",
    "print(tensorboard.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action=\"ignore\", message=\"^internal gelsd\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***Perceptrons***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "X = iris.data[:, (2,3)]\n",
    "y = (iris.target == 0).astype(np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plc = Perceptron()\n",
    "plc.fit(X,y)\n",
    "y_pred = plc.predict([[1, 0.5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***MLP using Keras API***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Classification***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import fashion_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f_mnist = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28), (60000,))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_full.shape, y_train_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 28, 28), (10000,))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dtype('uint8'), dtype('uint8'))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_full.dtype, y_train_full.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_valid = X_train_full[:5000]/255, X_train_full[5000:,]/255\n",
    "y_train, y_valid = y_train_full[:5000], y_train_full[5000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_train[0], cmap=\"binary\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class_names = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\",\n",
    "               \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ankle boot'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names[y_train[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x345.6 with 40 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_rows = 4\n",
    "n_cols = 10\n",
    "plt.figure(figsize = (n_cols * 1.2, n_rows * 1.2))\n",
    "for row in range(n_rows):\n",
    "    for col in range(n_cols):\n",
    "        index = n_cols * row + col\n",
    "        plt.subplot(n_rows, n_cols, index + 1)\n",
    "        plt.imshow(X_train[index], cmap = \"binary\", interpolation=\"nearest\")\n",
    "        plt.axis(\"off\")\n",
    "        plt.title(class_names[y_train[index]], fontsize = 12)\n",
    "plt.subplots_adjust(wspace=0.2, hspace=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape = [28,28]))\n",
    "model.add(keras.layers.Dense(300, activation = \"relu\"))\n",
    "model.add(keras.layers.Dense(100, activation = \"relu\"))\n",
    "model.add(keras.layers.Dense(10, activation = \"softmax\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**OR**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape = [28,28]),\n",
    "    keras.layers.Dense(300, activation = \"relu\"),\n",
    "    keras.layers.Dense(100, activation = \"relu\"),\n",
    "    keras.layers.Dense(10, activation = \"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_1 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 300)               235500    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 266,610\n",
      "Trainable params: 266,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.layers.core.Flatten at 0x14d5c0358>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x14d5c02e8>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x14d5c0f98>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x12dd6d320>]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.layers.core.Dense at 0x14d5c02e8>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden1 = model.layers[1]\n",
    "hidden1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dense_3'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden1.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_layer('dense_3') is hidden1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.0260957 ,  0.03249761,  0.05593722, ...,  0.04091412,\n",
       "        -0.04631817, -0.02813834],\n",
       "       [ 0.07125302, -0.02136759, -0.04251856, ..., -0.03867264,\n",
       "        -0.06963521, -0.05146851],\n",
       "       [ 0.06329951,  0.03660078, -0.0158308 , ..., -0.0631596 ,\n",
       "        -0.01702745, -0.00754762],\n",
       "       ...,\n",
       "       [-0.06919503, -0.05404519, -0.06558667, ..., -0.00795472,\n",
       "         0.04042177,  0.06157221],\n",
       "       [ 0.06511006,  0.07307073, -0.00038353, ..., -0.06199232,\n",
       "         0.0393438 , -0.06854922],\n",
       "       [ 0.02492436,  0.0532236 ,  0.01067107, ..., -0.03559567,\n",
       "        -0.06442454, -0.02774644]], dtype=float32)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights, biases = hidden1.get_weights()\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784, 300)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biases.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss = \"sparse_categorical_crossentropy\", optimizer = \"sgd\", metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5000 samples, validate on 55000 samples\n",
      "Epoch 1/30\n",
      "5000/5000 [==============================] - 3s 512us/step - loss: 0.1754 - acc: 0.9448 - val_loss: 0.4798 - val_acc: 0.8485\n",
      "Epoch 2/30\n",
      "5000/5000 [==============================] - 2s 473us/step - loss: 0.1669 - acc: 0.9504 - val_loss: 0.4785 - val_acc: 0.8456\n",
      "Epoch 3/30\n",
      "5000/5000 [==============================] - 2s 473us/step - loss: 0.1683 - acc: 0.9500 - val_loss: 0.4816 - val_acc: 0.8476\n",
      "Epoch 4/30\n",
      "5000/5000 [==============================] - 2s 470us/step - loss: 0.1590 - acc: 0.9552 - val_loss: 0.4919 - val_acc: 0.8447\n",
      "Epoch 5/30\n",
      "5000/5000 [==============================] - 2s 460us/step - loss: 0.1570 - acc: 0.9548 - val_loss: 0.5186 - val_acc: 0.8336\n",
      "Epoch 6/30\n",
      "5000/5000 [==============================] - 2s 465us/step - loss: 0.1586 - acc: 0.9486 - val_loss: 0.5461 - val_acc: 0.8383\n",
      "Epoch 7/30\n",
      "5000/5000 [==============================] - 2s 459us/step - loss: 0.1570 - acc: 0.9492 - val_loss: 0.5890 - val_acc: 0.8239\n",
      "Epoch 8/30\n",
      "5000/5000 [==============================] - 2s 475us/step - loss: 0.1521 - acc: 0.9526 - val_loss: 0.5140 - val_acc: 0.8352\n",
      "Epoch 9/30\n",
      "5000/5000 [==============================] - 2s 458us/step - loss: 0.1585 - acc: 0.9500 - val_loss: 0.5644 - val_acc: 0.8353\n",
      "Epoch 10/30\n",
      "5000/5000 [==============================] - 2s 459us/step - loss: 0.1504 - acc: 0.9564 - val_loss: 0.5012 - val_acc: 0.8487\n",
      "Epoch 11/30\n",
      "5000/5000 [==============================] - 2s 475us/step - loss: 0.1437 - acc: 0.9564 - val_loss: 0.7061 - val_acc: 0.7983\n",
      "Epoch 12/30\n",
      "5000/5000 [==============================] - 2s 466us/step - loss: 0.1495 - acc: 0.9564 - val_loss: 0.7944 - val_acc: 0.7720\n",
      "Epoch 13/30\n",
      "5000/5000 [==============================] - 2s 469us/step - loss: 0.1479 - acc: 0.9558 - val_loss: 0.7538 - val_acc: 0.7796\n",
      "Epoch 14/30\n",
      "5000/5000 [==============================] - 2s 469us/step - loss: 0.1412 - acc: 0.9596 - val_loss: 0.4868 - val_acc: 0.8507\n",
      "Epoch 15/30\n",
      "5000/5000 [==============================] - 2s 471us/step - loss: 0.1487 - acc: 0.9550 - val_loss: 0.4889 - val_acc: 0.8509\n",
      "Epoch 16/30\n",
      "5000/5000 [==============================] - 2s 459us/step - loss: 0.1446 - acc: 0.9574 - val_loss: 0.5091 - val_acc: 0.8441\n",
      "Epoch 17/30\n",
      "5000/5000 [==============================] - 2s 463us/step - loss: 0.1362 - acc: 0.9616 - val_loss: 0.5250 - val_acc: 0.8363\n",
      "Epoch 18/30\n",
      "5000/5000 [==============================] - 2s 488us/step - loss: 0.1347 - acc: 0.9596 - val_loss: 0.5026 - val_acc: 0.8497\n",
      "Epoch 19/30\n",
      "5000/5000 [==============================] - 2s 474us/step - loss: 0.1365 - acc: 0.9598 - val_loss: 0.5362 - val_acc: 0.8361\n",
      "Epoch 20/30\n",
      "5000/5000 [==============================] - 2s 473us/step - loss: 0.1295 - acc: 0.9622 - val_loss: 0.6070 - val_acc: 0.8338\n",
      "Epoch 21/30\n",
      "5000/5000 [==============================] - 3s 503us/step - loss: 0.1318 - acc: 0.9608 - val_loss: 0.5161 - val_acc: 0.8443\n",
      "Epoch 22/30\n",
      "5000/5000 [==============================] - 2s 483us/step - loss: 0.1266 - acc: 0.9630 - val_loss: 0.5607 - val_acc: 0.8411\n",
      "Epoch 23/30\n",
      "5000/5000 [==============================] - 2s 495us/step - loss: 0.1292 - acc: 0.9620 - val_loss: 0.7694 - val_acc: 0.7923\n",
      "Epoch 24/30\n",
      "5000/5000 [==============================] - 3s 509us/step - loss: 0.1270 - acc: 0.9646 - val_loss: 0.5402 - val_acc: 0.8408\n",
      "Epoch 25/30\n",
      "5000/5000 [==============================] - 2s 467us/step - loss: 0.1311 - acc: 0.9624 - val_loss: 0.5558 - val_acc: 0.8361\n",
      "Epoch 26/30\n",
      "5000/5000 [==============================] - 2s 474us/step - loss: 0.1223 - acc: 0.9680 - val_loss: 0.5458 - val_acc: 0.8386\n",
      "Epoch 27/30\n",
      "5000/5000 [==============================] - 3s 526us/step - loss: 0.1183 - acc: 0.9652 - val_loss: 1.0868 - val_acc: 0.7659\n",
      "Epoch 28/30\n",
      "5000/5000 [==============================] - 2s 477us/step - loss: 0.1277 - acc: 0.9632 - val_loss: 0.5785 - val_acc: 0.8278\n",
      "Epoch 29/30\n",
      "5000/5000 [==============================] - 2s 462us/step - loss: 0.1148 - acc: 0.9686 - val_loss: 1.0622 - val_acc: 0.7599\n",
      "Epoch 30/30\n",
      "5000/5000 [==============================] - 2s 462us/step - loss: 0.1180 - acc: 0.9670 - val_loss: 0.5107 - val_acc: 0.8473\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs = 30, validation_data = (X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_size': 32,\n",
       " 'do_validation': True,\n",
       " 'epochs': 30,\n",
       " 'metrics': ['loss', 'acc', 'val_loss', 'val_acc'],\n",
       " 'samples': 5000,\n",
       " 'steps': None,\n",
       " 'validation_steps': None,\n",
       " 'verbose': 1}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.epoch[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acc': [0.9448,\n",
       "  0.9504,\n",
       "  0.95,\n",
       "  0.9552,\n",
       "  0.9548,\n",
       "  0.9486,\n",
       "  0.9492,\n",
       "  0.9526,\n",
       "  0.95,\n",
       "  0.9564,\n",
       "  0.9564,\n",
       "  0.9564,\n",
       "  0.9558,\n",
       "  0.9596,\n",
       "  0.955,\n",
       "  0.9574,\n",
       "  0.9616,\n",
       "  0.9596,\n",
       "  0.9598,\n",
       "  0.9622,\n",
       "  0.9608,\n",
       "  0.963,\n",
       "  0.962,\n",
       "  0.9646,\n",
       "  0.9624,\n",
       "  0.968,\n",
       "  0.9652,\n",
       "  0.9632,\n",
       "  0.9686,\n",
       "  0.967],\n",
       " 'loss': [0.1753633601427078,\n",
       "  0.16692601482868194,\n",
       "  0.1682692233324051,\n",
       "  0.15899397564530374,\n",
       "  0.15703924816846848,\n",
       "  0.1585779419183731,\n",
       "  0.1570442094564438,\n",
       "  0.1521025405406952,\n",
       "  0.1584560399889946,\n",
       "  0.1503567211985588,\n",
       "  0.1436868385076523,\n",
       "  0.1495301857471466,\n",
       "  0.14789509885311128,\n",
       "  0.1411757529884577,\n",
       "  0.14873621201515197,\n",
       "  0.14461903991699218,\n",
       "  0.13624492441415786,\n",
       "  0.13468658224344254,\n",
       "  0.13653679294586182,\n",
       "  0.12953660229444502,\n",
       "  0.13183316848278046,\n",
       "  0.12660247473716735,\n",
       "  0.12921654212474823,\n",
       "  0.12696554313376546,\n",
       "  0.13107603429555892,\n",
       "  0.12233842308521271,\n",
       "  0.11826180015206338,\n",
       "  0.1277181262731552,\n",
       "  0.11484499058127404,\n",
       "  0.1179760050714016],\n",
       " 'val_acc': [0.8484545454458757,\n",
       "  0.8455636363549666,\n",
       "  0.8475636363723061,\n",
       "  0.8446545454545454,\n",
       "  0.8335818181731485,\n",
       "  0.8382909090822394,\n",
       "  0.8239090909090909,\n",
       "  0.8351636363549666,\n",
       "  0.8353454545367848,\n",
       "  0.8487454545541243,\n",
       "  0.7983454545541243,\n",
       "  0.7720181818268516,\n",
       "  0.7795636363636363,\n",
       "  0.8507272727359425,\n",
       "  0.8509272727359425,\n",
       "  0.8441454545454545,\n",
       "  0.8362545454458757,\n",
       "  0.8497272727359425,\n",
       "  0.836127272718603,\n",
       "  0.8337636363723061,\n",
       "  0.8442545454545455,\n",
       "  0.8411272727272727,\n",
       "  0.7922545454632153,\n",
       "  0.8407818181818182,\n",
       "  0.8361090909090909,\n",
       "  0.8386,\n",
       "  0.7659454545367848,\n",
       "  0.8278181818181818,\n",
       "  0.7598909090822393,\n",
       "  0.8472909090995788],\n",
       " 'val_loss': [0.47983096793781627,\n",
       "  0.47848457275737416,\n",
       "  0.4816292576009577,\n",
       "  0.491900920642506,\n",
       "  0.5185854533065449,\n",
       "  0.5461150059266524,\n",
       "  0.5889672202522105,\n",
       "  0.5139618318774484,\n",
       "  0.5644389790860089,\n",
       "  0.5011923755125566,\n",
       "  0.7060902780966325,\n",
       "  0.7943593423149803,\n",
       "  0.7538098672433333,\n",
       "  0.486752496786551,\n",
       "  0.48892846071503376,\n",
       "  0.5091092040603811,\n",
       "  0.5250380600279028,\n",
       "  0.5026031789021058,\n",
       "  0.5362317555232482,\n",
       "  0.607034926238927,\n",
       "  0.5160524253693494,\n",
       "  0.560732663119923,\n",
       "  0.7694100802464918,\n",
       "  0.5402363888372075,\n",
       "  0.55579148032882,\n",
       "  0.5458053689956665,\n",
       "  1.086801888370514,\n",
       "  0.5785191504911943,\n",
       "  1.0622469803506678,\n",
       "  0.5106645260377364]}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(history.history).plot(figsize = (8,5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 39us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3.184693244552612, 0.8001]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new = X_test[:3]\n",
    "y_proba = model.predict(X_new)\n",
    "y_proba.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 2, 1])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict_classes(X_new)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 2, 1], dtype=uint8)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_new = y_test[:3]\n",
    "y_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x216 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_rows = 1\n",
    "n_cols = 3\n",
    "plt.figure(figsize = (n_cols * 3, n_rows * 3))\n",
    "for row in range(n_rows):\n",
    "    for col in range(n_cols):\n",
    "        index = n_cols * row + col\n",
    "        plt.subplot(n_rows, n_cols, index + 1)\n",
    "        plt.imshow(X_test[index], cmap = \"binary\", interpolation=\"nearest\")\n",
    "        plt.axis(\"off\")\n",
    "        plt.title(class_names[y_test[index]], fontsize = 12)\n",
    "plt.subplots_adjust(wspace=0.2, hspace=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Regression***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "housing = fetch_california_housing()\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(housing[\"data\"], housing[\"target\"])\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_full, y_train_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11610, 8) (11610,)\n",
      "(3870, 8) (3870,)\n",
      "(5160, 8) (5160,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, y_train.shape)\n",
    "print(X_val.shape, y_val.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8,)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/20\n",
      "11610/11610 [==============================] - 1s 49us/step - loss: 1.1057 - val_loss: 0.5479\n",
      "Epoch 2/20\n",
      "11610/11610 [==============================] - 0s 32us/step - loss: 1.2678 - val_loss: 0.4870\n",
      "Epoch 3/20\n",
      "11610/11610 [==============================] - 0s 33us/step - loss: 0.4930 - val_loss: 0.5414\n",
      "Epoch 4/20\n",
      "11610/11610 [==============================] - 0s 32us/step - loss: 0.4455 - val_loss: 0.3929\n",
      "Epoch 5/20\n",
      "11610/11610 [==============================] - 0s 32us/step - loss: 0.4117 - val_loss: 0.3876\n",
      "Epoch 6/20\n",
      "11610/11610 [==============================] - 0s 32us/step - loss: 0.4015 - val_loss: 0.3769\n",
      "Epoch 7/20\n",
      "11610/11610 [==============================] - 0s 33us/step - loss: 0.3989 - val_loss: 0.3764\n",
      "Epoch 8/20\n",
      "11610/11610 [==============================] - 0s 32us/step - loss: 0.3926 - val_loss: 0.3718\n",
      "Epoch 9/20\n",
      "11610/11610 [==============================] - 0s 32us/step - loss: 0.3868 - val_loss: 0.3677\n",
      "Epoch 10/20\n",
      "11610/11610 [==============================] - 0s 34us/step - loss: 0.3822 - val_loss: 0.3638\n",
      "Epoch 11/20\n",
      "11610/11610 [==============================] - 0s 37us/step - loss: 0.3824 - val_loss: 0.3615\n",
      "Epoch 12/20\n",
      "11610/11610 [==============================] - 0s 36us/step - loss: 0.3812 - val_loss: 0.3618\n",
      "Epoch 13/20\n",
      "11610/11610 [==============================] - 0s 35us/step - loss: 0.3775 - val_loss: 0.3646\n",
      "Epoch 14/20\n",
      "11610/11610 [==============================] - 0s 32us/step - loss: 0.3787 - val_loss: 0.3585\n",
      "Epoch 15/20\n",
      "11610/11610 [==============================] - 0s 33us/step - loss: 0.3721 - val_loss: 0.3593\n",
      "Epoch 16/20\n",
      "11610/11610 [==============================] - 0s 36us/step - loss: 0.3724 - val_loss: 0.3659\n",
      "Epoch 17/20\n",
      "11610/11610 [==============================] - 0s 34us/step - loss: 0.3702 - val_loss: 0.3536\n",
      "Epoch 18/20\n",
      "11610/11610 [==============================] - 0s 40us/step - loss: 0.3707 - val_loss: 0.3582\n",
      "Epoch 19/20\n",
      "11610/11610 [==============================] - 0s 35us/step - loss: 0.3785 - val_loss: 0.3508\n",
      "Epoch 20/20\n",
      "11610/11610 [==============================] - 0s 33us/step - loss: 0.3650 - val_loss: 0.3554\n",
      "5160/5160 [==============================] - 0s 13us/step\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation = \"relu\", input_shape = X_train.shape[1:]),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(loss = \"mean_squared_error\", optimizer = \"sgd\")\n",
    "history = model.fit(X_train, y_train, epochs = 20, validation_data = (X_val, y_val))\n",
    "mse_test = model.evaluate(X_test, y_test)\n",
    "X_new = X_test[:3]\n",
    "y_pred = model.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3578335714663646"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_size': 32,\n",
       " 'do_validation': True,\n",
       " 'epochs': 20,\n",
       " 'metrics': ['loss', 'val_loss'],\n",
       " 'samples': 11610,\n",
       " 'steps': None,\n",
       " 'validation_steps': None,\n",
       " 'verbose': 1}"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [1.105666008907387,\n",
       "  1.2677589136757386,\n",
       "  0.492960241290642,\n",
       "  0.44545401182285577,\n",
       "  0.4116706028773187,\n",
       "  0.40154921636306246,\n",
       "  0.3988724130479351,\n",
       "  0.39255916521941453,\n",
       "  0.38677885863516065,\n",
       "  0.3821852838474548,\n",
       "  0.3823537046081747,\n",
       "  0.38116063101347103,\n",
       "  0.37751490060467846,\n",
       "  0.3787041958604364,\n",
       "  0.37212090745350085,\n",
       "  0.372393982231771,\n",
       "  0.3701538502194571,\n",
       "  0.37066272889407514,\n",
       "  0.37848038532218475,\n",
       "  0.3649585146363905],\n",
       " 'val_loss': [0.5478896946716062,\n",
       "  0.48700637148948295,\n",
       "  0.5413703060581394,\n",
       "  0.3928633645369409,\n",
       "  0.3875938989549336,\n",
       "  0.37689439737519553,\n",
       "  0.3764384098755297,\n",
       "  0.37175409596711784,\n",
       "  0.3677070631845361,\n",
       "  0.3638416927914287,\n",
       "  0.3615226058996925,\n",
       "  0.3618399749276558,\n",
       "  0.36459634416479164,\n",
       "  0.35848414036192633,\n",
       "  0.35933705679205963,\n",
       "  0.3659134576949038,\n",
       "  0.3536282114819347,\n",
       "  0.3581904361568372,\n",
       "  0.3508175761200661,\n",
       "  0.3554181328962632]}"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***Non Sequential API- Functional API***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_ = keras.layers.Input(shape = X_train.shape[1:])\n",
    "hidden1 = keras.layers.Dense(30, activation = \"relu\")(input_)\n",
    "hidden2 = keras.layers.Dense(30, activation = \"relu\")(hidden1)\n",
    "concat = keras.layers.Concatenate()([input_, hidden2])\n",
    "output = keras.layers.Dense(1)(concat)\n",
    "model = keras.Model(inputs = [input_], outputs = [output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 8)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 30)           270         input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Dense)                (None, 30)           930         dense_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 38)           0           input_3[0][0]                    \n",
      "                                                                 dense_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_16 (Dense)                (None, 1)            39          concatenate_2[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 1,239\n",
      "Trainable params: 1,239\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.engine.input_layer.InputLayer at 0x14f763780>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x14f763908>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x14f763c50>,\n",
       " <tensorflow.python.keras.layers.merge.Concatenate at 0x14f763e48>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x14f7712e8>]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/20\n",
      "11610/11610 [==============================] - 1s 76us/step - loss: 2.1593 - val_loss: 0.8916\n",
      "Epoch 2/20\n",
      "11610/11610 [==============================] - 0s 40us/step - loss: 0.8255 - val_loss: 0.7621\n",
      "Epoch 3/20\n",
      "11610/11610 [==============================] - 0s 40us/step - loss: 0.7394 - val_loss: 0.7030\n",
      "Epoch 4/20\n",
      "11610/11610 [==============================] - 0s 40us/step - loss: 0.6877 - val_loss: 0.6588\n",
      "Epoch 5/20\n",
      "11610/11610 [==============================] - 0s 40us/step - loss: 0.6517 - val_loss: 0.6282\n",
      "Epoch 6/20\n",
      "11610/11610 [==============================] - 0s 40us/step - loss: 0.6223 - val_loss: 0.6031\n",
      "Epoch 7/20\n",
      "11610/11610 [==============================] - 0s 41us/step - loss: 0.5995 - val_loss: 0.5817\n",
      "Epoch 8/20\n",
      "11610/11610 [==============================] - 0s 41us/step - loss: 0.5810 - val_loss: 0.5650\n",
      "Epoch 9/20\n",
      "11610/11610 [==============================] - 0s 41us/step - loss: 0.5648 - val_loss: 0.5489\n",
      "Epoch 10/20\n",
      "11610/11610 [==============================] - 0s 41us/step - loss: 0.5522 - val_loss: 0.5369\n",
      "Epoch 11/20\n",
      "11610/11610 [==============================] - 0s 42us/step - loss: 0.5398 - val_loss: 0.5269\n",
      "Epoch 12/20\n",
      "11610/11610 [==============================] - 0s 42us/step - loss: 0.5300 - val_loss: 0.5164\n",
      "Epoch 13/20\n",
      "11610/11610 [==============================] - 0s 42us/step - loss: 0.5205 - val_loss: 0.5116\n",
      "Epoch 14/20\n",
      "11610/11610 [==============================] - 1s 56us/step - loss: 0.5142 - val_loss: 0.5001\n",
      "Epoch 15/20\n",
      "11610/11610 [==============================] - 0s 43us/step - loss: 0.5066 - val_loss: 0.4943\n",
      "Epoch 16/20\n",
      "11610/11610 [==============================] - 1s 54us/step - loss: 0.4990 - val_loss: 0.4874\n",
      "Epoch 17/20\n",
      "11610/11610 [==============================] - 1s 43us/step - loss: 0.4941 - val_loss: 0.4837\n",
      "Epoch 18/20\n",
      "11610/11610 [==============================] - 1s 45us/step - loss: 0.4889 - val_loss: 0.4800\n",
      "Epoch 19/20\n",
      "11610/11610 [==============================] - 1s 47us/step - loss: 0.4839 - val_loss: 0.4765\n",
      "Epoch 20/20\n",
      "11610/11610 [==============================] - 0s 42us/step - loss: 0.4796 - val_loss: 0.4673\n",
      "5160/5160 [==============================] - 0s 27us/step\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss = \"mean_squared_error\", optimizer = keras.optimizers.SGD(lr=1e-3))\n",
    "history = model.fit(X_train, y_train, epochs = 20, validation_data = (X_val, y_val))\n",
    "mse_test = model.evaluate(X_test, y_test)\n",
    "X_new = X_test[:3]\n",
    "y_pred = model.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45607281636822133"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Multiple Inputs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_A = keras.layers.Input(shape = [5], name = \"wide_input\")\n",
    "input_B = keras.layers.Input(shape = [6], name = \"deep_input\")\n",
    "hidden1 = keras.layers.Dense(30, activation = \"relu\")(input_B)\n",
    "hidden2 = keras.layers.Dense(30, activation = \"relu\")(hidden1)\n",
    "concat = keras.layers.Concatenate()([input_A, hidden2])\n",
    "output = keras.layers.Dense(1)(concat)\n",
    "model = keras.Model(inputs = [input_A, input_B], outputs = output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "deep_input (InputLayer)         (None, 6)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_17 (Dense)                (None, 30)           210         deep_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "wide_input (InputLayer)         (None, 5)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_18 (Dense)                (None, 30)           930         dense_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 35)           0           wide_input[0][0]                 \n",
      "                                                                 dense_18[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_19 (Dense)                (None, 1)            36          concatenate_3[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 1,176\n",
      "Trainable params: 1,176\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.engine.input_layer.InputLayer at 0x1534db710>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x1534db7f0>,\n",
       " <tensorflow.python.keras.engine.input_layer.InputLayer at 0x1534db6a0>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x150fd5860>,\n",
       " <tensorflow.python.keras.layers.merge.Concatenate at 0x150fd5898>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x1534f6828>]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss = \"mse\", optimizer = keras.optimizers.SGD(lr=1e-3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_A, X_train_B = X_train[:, :5], X_train[:, 2:]\n",
    "X_val_A, X_val_B = X_val[:, :5], X_val[:, 2:]\n",
    "X_test_A, X_test_B = X_test[:, :5], X_test[:, 2:]\n",
    "X_new_A, X_new_B = X_test_A[:3], X_test_B[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/20\n",
      "11610/11610 [==============================] - 1s 84us/step - loss: 1.9676 - val_loss: 0.9824\n",
      "Epoch 2/20\n",
      "11610/11610 [==============================] - 0s 40us/step - loss: 0.8604 - val_loss: 0.7564\n",
      "Epoch 3/20\n",
      "11610/11610 [==============================] - 0s 41us/step - loss: 0.7138 - val_loss: 0.6715\n",
      "Epoch 4/20\n",
      "11610/11610 [==============================] - 0s 42us/step - loss: 0.6494 - val_loss: 0.6222\n",
      "Epoch 5/20\n",
      "11610/11610 [==============================] - 0s 42us/step - loss: 0.6082 - val_loss: 0.5868\n",
      "Epoch 6/20\n",
      "11610/11610 [==============================] - 0s 42us/step - loss: 0.5777 - val_loss: 0.5604\n",
      "Epoch 7/20\n",
      "11610/11610 [==============================] - 0s 42us/step - loss: 0.5550 - val_loss: 0.5388\n",
      "Epoch 8/20\n",
      "11610/11610 [==============================] - 0s 42us/step - loss: 0.5376 - val_loss: 0.5233\n",
      "Epoch 9/20\n",
      "11610/11610 [==============================] - 0s 42us/step - loss: 0.5233 - val_loss: 0.5128\n",
      "Epoch 10/20\n",
      "11610/11610 [==============================] - 0s 43us/step - loss: 0.5140 - val_loss: 0.5002\n",
      "Epoch 11/20\n",
      "11610/11610 [==============================] - 1s 49us/step - loss: 0.5042 - val_loss: 0.4912\n",
      "Epoch 12/20\n",
      "11610/11610 [==============================] - 1s 47us/step - loss: 0.4980 - val_loss: 0.4844\n",
      "Epoch 13/20\n",
      "11610/11610 [==============================] - 1s 46us/step - loss: 0.4917 - val_loss: 0.4782\n",
      "Epoch 14/20\n",
      "11610/11610 [==============================] - 1s 48us/step - loss: 0.4840 - val_loss: 0.4757\n",
      "Epoch 15/20\n",
      "11610/11610 [==============================] - 1s 56us/step - loss: 0.4796 - val_loss: 0.4684\n",
      "Epoch 16/20\n",
      "11610/11610 [==============================] - 0s 40us/step - loss: 0.4758 - val_loss: 0.4644\n",
      "Epoch 17/20\n",
      "11610/11610 [==============================] - 1s 56us/step - loss: 0.4713 - val_loss: 0.4597\n",
      "Epoch 18/20\n",
      "11610/11610 [==============================] - 1s 46us/step - loss: 0.4672 - val_loss: 0.4563\n",
      "Epoch 19/20\n",
      "11610/11610 [==============================] - 0s 42us/step - loss: 0.4635 - val_loss: 0.4521\n",
      "Epoch 20/20\n",
      "11610/11610 [==============================] - 0s 42us/step - loss: 0.4604 - val_loss: 0.4494\n"
     ]
    }
   ],
   "source": [
    "history = model.fit((X_train_A, X_train_B), y_train, epochs = 20, validation_data = ((X_val_A, X_val_B), y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_size': 32,\n",
       " 'do_validation': True,\n",
       " 'epochs': 20,\n",
       " 'metrics': ['loss', 'val_loss'],\n",
       " 'samples': 11610,\n",
       " 'steps': None,\n",
       " 'validation_steps': None,\n",
       " 'verbose': 1}"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5160/5160 [==============================] - 0s 19us/step\n"
     ]
    }
   ],
   "source": [
    "mse_test = model.evaluate((X_test_A, X_test_B), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4454769575318625"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict((X_new_A, X_new_B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.6377578],\n",
       "       [2.5114546],\n",
       "       [3.3146057]], dtype=float32)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 2, 1], dtype=uint8)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Multiple Outputs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_A = keras.layers.Input(shape = [5], name = \"wide_input\")\n",
    "input_B = keras.layers.Input(shape = [6], name = \"deep_input\")\n",
    "hidden1 = keras.layers.Dense(30, activation = \"relu\")(input_B)\n",
    "hidden2 = keras.layers.Dense(30, activation = \"relu\")(hidden1)\n",
    "concat = keras.layers.Concatenate()([input_A, hidden2])\n",
    "output = keras.layers.Dense(1, name = \"main_output\")(concat)\n",
    "aux_output = keras.layers.Dense(1, name = \"auxiliary_output\")(hidden2)\n",
    "model = keras.Model(inputs = [input_A, input_B], outputs = [output, aux_output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "deep_input (InputLayer)         (None, 6)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_24 (Dense)                (None, 30)           210         deep_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "wide_input (InputLayer)         (None, 5)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_25 (Dense)                (None, 30)           930         dense_24[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 35)           0           wide_input[0][0]                 \n",
      "                                                                 dense_25[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "main_output (Dense)             (None, 1)            36          concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "auxiliary_output (Dense)        (None, 1)            31          dense_25[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 1,207\n",
      "Trainable params: 1,207\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.engine.input_layer.InputLayer at 0x153f10390>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x153f10550>,\n",
       " <tensorflow.python.keras.engine.input_layer.InputLayer at 0x153f10320>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x153f104a8>,\n",
       " <tensorflow.python.keras.layers.merge.Concatenate at 0x153f105c0>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x153f109e8>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x153f10978>]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss = [\"mse\", \"mse\"], loss_weights = [0.9, 0.1], optimizer = keras.optimizers.SGD(lr=1e-3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/20\n",
      "11610/11610 [==============================] - 1s 118us/step - loss: 1.9827 - main_output_loss: 1.7448 - auxiliary_output_loss: 4.1241 - val_loss: 1.0042 - val_main_output_loss: 0.7861 - val_auxiliary_output_loss: 2.9671\n",
      "Epoch 2/20\n",
      "11610/11610 [==============================] - 1s 55us/step - loss: 0.9211 - main_output_loss: 0.7380 - auxiliary_output_loss: 2.5696 - val_loss: 0.8219 - val_main_output_loss: 0.6711 - val_auxiliary_output_loss: 2.1790\n",
      "Epoch 3/20\n",
      "11610/11610 [==============================] - 1s 54us/step - loss: 0.7929 - main_output_loss: 0.6569 - auxiliary_output_loss: 2.0163 - val_loss: 0.7486 - val_main_output_loss: 0.6307 - val_auxiliary_output_loss: 1.8096\n",
      "Epoch 4/20\n",
      "11610/11610 [==============================] - 1s 57us/step - loss: 0.7351 - main_output_loss: 0.6223 - auxiliary_output_loss: 1.7498 - val_loss: 0.7067 - val_main_output_loss: 0.6031 - val_auxiliary_output_loss: 1.6389\n",
      "Epoch 5/20\n",
      "11610/11610 [==============================] - 1s 54us/step - loss: 0.6995 - main_output_loss: 0.5975 - auxiliary_output_loss: 1.6180 - val_loss: 0.6776 - val_main_output_loss: 0.5814 - val_auxiliary_output_loss: 1.5437\n",
      "Epoch 6/20\n",
      "11610/11610 [==============================] - 1s 53us/step - loss: 0.6740 - main_output_loss: 0.5777 - auxiliary_output_loss: 1.5415 - val_loss: 0.6549 - val_main_output_loss: 0.5631 - val_auxiliary_output_loss: 1.4809\n",
      "Epoch 7/20\n",
      "11610/11610 [==============================] - 1s 57us/step - loss: 0.6539 - main_output_loss: 0.5611 - auxiliary_output_loss: 1.4898 - val_loss: 0.6365 - val_main_output_loss: 0.5474 - val_auxiliary_output_loss: 1.4384\n",
      "Epoch 8/20\n",
      "11610/11610 [==============================] - 1s 53us/step - loss: 0.6374 - main_output_loss: 0.5471 - auxiliary_output_loss: 1.4508 - val_loss: 0.6213 - val_main_output_loss: 0.5343 - val_auxiliary_output_loss: 1.4043\n",
      "Epoch 9/20\n",
      "11610/11610 [==============================] - 1s 54us/step - loss: 0.6237 - main_output_loss: 0.5354 - auxiliary_output_loss: 1.4184 - val_loss: 0.6079 - val_main_output_loss: 0.5231 - val_auxiliary_output_loss: 1.3706\n",
      "Epoch 10/20\n",
      "11610/11610 [==============================] - 1s 67us/step - loss: 0.6110 - main_output_loss: 0.5248 - auxiliary_output_loss: 1.3864 - val_loss: 0.5964 - val_main_output_loss: 0.5134 - val_auxiliary_output_loss: 1.3432\n",
      "Epoch 11/20\n",
      "11610/11610 [==============================] - 1s 53us/step - loss: 0.6011 - main_output_loss: 0.5168 - auxiliary_output_loss: 1.3595 - val_loss: 0.5862 - val_main_output_loss: 0.5052 - val_auxiliary_output_loss: 1.3154\n",
      "Epoch 12/20\n",
      "11610/11610 [==============================] - 1s 53us/step - loss: 0.5915 - main_output_loss: 0.5093 - auxiliary_output_loss: 1.3312 - val_loss: 0.5783 - val_main_output_loss: 0.4989 - val_auxiliary_output_loss: 1.2931\n",
      "Epoch 13/20\n",
      "11610/11610 [==============================] - 1s 53us/step - loss: 0.5830 - main_output_loss: 0.5025 - auxiliary_output_loss: 1.3074 - val_loss: 0.5688 - val_main_output_loss: 0.4915 - val_auxiliary_output_loss: 1.2650\n",
      "Epoch 14/20\n",
      "11610/11610 [==============================] - 1s 54us/step - loss: 0.5755 - main_output_loss: 0.4970 - auxiliary_output_loss: 1.2821 - val_loss: 0.5612 - val_main_output_loss: 0.4856 - val_auxiliary_output_loss: 1.2409\n",
      "Epoch 15/20\n",
      "11610/11610 [==============================] - 1s 55us/step - loss: 0.5684 - main_output_loss: 0.4918 - auxiliary_output_loss: 1.2579 - val_loss: 0.5547 - val_main_output_loss: 0.4808 - val_auxiliary_output_loss: 1.2192\n",
      "Epoch 16/20\n",
      "11610/11610 [==============================] - 1s 53us/step - loss: 0.5617 - main_output_loss: 0.4869 - auxiliary_output_loss: 1.2351 - val_loss: 0.5481 - val_main_output_loss: 0.4760 - val_auxiliary_output_loss: 1.1969\n",
      "Epoch 17/20\n",
      "11610/11610 [==============================] - 1s 60us/step - loss: 0.5550 - main_output_loss: 0.4820 - auxiliary_output_loss: 1.2113 - val_loss: 0.5413 - val_main_output_loss: 0.4710 - val_auxiliary_output_loss: 1.1743\n",
      "Epoch 18/20\n",
      "11610/11610 [==============================] - 1s 57us/step - loss: 0.5492 - main_output_loss: 0.4780 - auxiliary_output_loss: 1.1898 - val_loss: 0.5353 - val_main_output_loss: 0.4667 - val_auxiliary_output_loss: 1.1526\n",
      "Epoch 19/20\n",
      "11610/11610 [==============================] - 1s 53us/step - loss: 0.5431 - main_output_loss: 0.4737 - auxiliary_output_loss: 1.1672 - val_loss: 0.5292 - val_main_output_loss: 0.4623 - val_auxiliary_output_loss: 1.1312\n",
      "Epoch 20/20\n",
      "11610/11610 [==============================] - 1s 57us/step - loss: 0.5378 - main_output_loss: 0.4702 - auxiliary_output_loss: 1.1457 - val_loss: 0.5238 - val_main_output_loss: 0.4587 - val_auxiliary_output_loss: 1.1103\n"
     ]
    }
   ],
   "source": [
    "history = model.fit([X_train_A, X_train_B], [y_train, y_train], epochs = 20, \n",
    "                    validation_data = ([X_val_A, X_val_B], [y_val, y_val]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_size': 32,\n",
       " 'do_validation': True,\n",
       " 'epochs': 20,\n",
       " 'metrics': ['loss',\n",
       "  'main_output_loss',\n",
       "  'auxiliary_output_loss',\n",
       "  'val_loss',\n",
       "  'val_main_output_loss',\n",
       "  'val_auxiliary_output_loss'],\n",
       " 'samples': 11610,\n",
       " 'steps': None,\n",
       " 'validation_steps': None,\n",
       " 'verbose': 1}"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5160/5160 [==============================] - 0s 26us/step\n"
     ]
    }
   ],
   "source": [
    "total_loss, main_loss, aux_loss = model.evaluate([X_test_A, X_test_B], [y_test, y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5239139781903851, 0.4581315745678983, 1.1159557045892228)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_loss, main_loss, aux_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred_main, y_pred_aux = model.predict([X_new_A, X_new_B])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[2.5331333],\n",
       "        [2.5197074],\n",
       "        [3.3657305]], dtype=float32), array([[2.1387827],\n",
       "        [2.4847882],\n",
       "        [2.0132048]], dtype=float32), array([9, 2, 1], dtype=uint8))"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_main, y_pred_aux, y_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***Subclassing API***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class WideAndDeepModel(keras.models.Model):\n",
    "    def __init__(self, units=30, activation=\"relu\", **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.hidden1 = keras.layers.Dense(units, activation=activation)\n",
    "        self.hidden2 = keras.layers.Dense(units, activation=activation)\n",
    "        self.main_output = keras.layers.Dense(1)\n",
    "        self.aux_output = keras.layers.Dense(1)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        input_A, input_B = inputs\n",
    "        hidden1 = self.hidden1(input_B)\n",
    "        hidden2 = self.hidden2(hidden1)\n",
    "        concat = keras.layers.concatenate([input_A, hidden2])\n",
    "        main_output = self.main_output(concat)\n",
    "        aux_output = self.aux_output(hidden2)\n",
    "        return main_output, aux_output\n",
    "\n",
    "model = WideAndDeepModel(30, activation=\"relu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/10\n",
      "11610/11610 [==============================] - 1s 117us/step - loss: 2.5339 - output_1_loss: 2.3849 - output_2_loss: 3.8742 - val_loss: 1.2274 - val_output_1_loss: 1.0446 - val_output_2_loss: 2.8728\n",
      "Epoch 2/10\n",
      "11610/11610 [==============================] - 1s 61us/step - loss: 1.0520 - output_1_loss: 0.8886 - output_2_loss: 2.5225 - val_loss: 0.8640 - val_output_1_loss: 0.7412 - val_output_2_loss: 1.9688\n",
      "Epoch 3/10\n",
      "11610/11610 [==============================] - 1s 56us/step - loss: 0.8222 - output_1_loss: 0.7028 - output_2_loss: 1.8971 - val_loss: 0.7423 - val_output_1_loss: 0.6505 - val_output_2_loss: 1.5683\n",
      "Epoch 4/10\n",
      "11610/11610 [==============================] - 1s 58us/step - loss: 0.7353 - output_1_loss: 0.6392 - output_2_loss: 1.6005 - val_loss: 0.6841 - val_output_1_loss: 0.6081 - val_output_2_loss: 1.3685\n",
      "Epoch 5/10\n",
      "11610/11610 [==============================] - 1s 53us/step - loss: 0.6887 - output_1_loss: 0.6047 - output_2_loss: 1.4445 - val_loss: 0.6499 - val_output_1_loss: 0.5810 - val_output_2_loss: 1.2698\n",
      "Epoch 6/10\n",
      "11610/11610 [==============================] - 1s 57us/step - loss: 0.6580 - output_1_loss: 0.5809 - output_2_loss: 1.3519 - val_loss: 0.6243 - val_output_1_loss: 0.5595 - val_output_2_loss: 1.2076\n",
      "Epoch 7/10\n",
      "11610/11610 [==============================] - 1s 57us/step - loss: 0.6354 - output_1_loss: 0.5630 - output_2_loss: 1.2873 - val_loss: 0.6058 - val_output_1_loss: 0.5433 - val_output_2_loss: 1.1677\n",
      "Epoch 8/10\n",
      "11610/11610 [==============================] - 1s 55us/step - loss: 0.6168 - output_1_loss: 0.5480 - output_2_loss: 1.2367 - val_loss: 0.5907 - val_output_1_loss: 0.5305 - val_output_2_loss: 1.1330\n",
      "Epoch 9/10\n",
      "11610/11610 [==============================] - 1s 57us/step - loss: 0.6016 - output_1_loss: 0.5357 - output_2_loss: 1.1954 - val_loss: 0.5768 - val_output_1_loss: 0.5181 - val_output_2_loss: 1.1052\n",
      "Epoch 10/10\n",
      "11610/11610 [==============================] - 1s 57us/step - loss: 0.5884 - output_1_loss: 0.5249 - output_2_loss: 1.1597 - val_loss: 0.5661 - val_output_1_loss: 0.5089 - val_output_2_loss: 1.0802\n",
      "5160/5160 [==============================] - 0s 28us/step\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"mse\", loss_weights=[0.9, 0.1], optimizer=keras.optimizers.SGD(lr=1e-3))\n",
    "history = model.fit((X_train_A, X_train_B), (y_train, y_train), epochs=10,\n",
    "                    validation_data=((X_val_A, X_val_B), (y_val, y_val)))\n",
    "total_loss, main_loss, aux_loss = model.evaluate((X_test_A, X_test_B), (y_test, y_test))\n",
    "y_pred_main, y_pred_aux = model.predict((X_new_A, X_new_B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = WideAndDeepModel(30, activation=\"relu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***Saving & Loading Models***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(housing.data, housing.target, random_state=42)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_valid = scaler.transform(X_valid)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = X_test[:3]\n",
    "y_new = y_test[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "# tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=[8]),\n",
    "    keras.layers.Dense(30, activation=\"relu\"),\n",
    "    keras.layers.Dense(1)\n",
    "])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.4119 - val_loss: 1.1847\n",
      "Epoch 2/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.6658 - val_loss: 0.6214\n",
      "Epoch 3/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5995 - val_loss: 0.5649\n",
      "Epoch 4/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5578 - val_loss: 0.5224\n",
      "Epoch 5/10\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.5267 - val_loss: 0.5243\n",
      "Epoch 6/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5026 - val_loss: 0.5149\n",
      "Epoch 7/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4829 - val_loss: 0.5208\n",
      "Epoch 8/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4671 - val_loss: 0.5345\n",
      "Epoch 9/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4546 - val_loss: 0.4997\n",
      "Epoch 10/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4443 - val_loss: 0.4820\n",
      "162/162 [==============================] - 0s 988us/step - loss: 0.4349\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(lr=1e-3))\n",
    "history = model.fit(X_train, y_train, epochs=10, validation_data=(X_valid, y_valid))\n",
    "mse_test = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_ = \"/Users/cmeena/Desktop/ML Practice/TensorFlow Developer/Aurelion Book/Ch 10/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save(path_+\"my_keras_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = keras.models.load_model(path_+\"my_keras_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.69530135],\n",
       "       [1.5559335 ],\n",
       "       [3.6128306 ]], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/cmeena/Desktop/ML Practice/TensorFlow Developer/Aurelion Book/Ch 10\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(path_+\"my_keras_weights.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x1394b1e48>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_weights(path_+\"my_keras_weights.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***Callbacks***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=[8]),\n",
    "    keras.layers.Dense(30, activation=\"relu\"),\n",
    "    keras.layers.Dense(1)\n",
    "])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 2.2183\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.7800\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.6698\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.6280\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5949\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5663\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5419\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5205\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5021\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4862\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4730\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4613\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 0s 996us/step - loss: 0.4511\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4429\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4354\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 0s 966us/step - loss: 0.4287\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4230\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4181\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4135\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4091\n",
      "162/162 [==============================] - 0s 841us/step - loss: 0.3977\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3977367877960205"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(lr=1e-3))\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(path_+\"my_keras_model.h5\")\n",
    "history = model.fit(X_train, y_train, epochs = 20, callbacks = [checkpoint_cb])\n",
    "mse_test = model.evaluate(X_test, y_test)\n",
    "mse_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4057 - val_loss: 0.3865\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4022 - val_loss: 0.3837\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3988 - val_loss: 0.4005\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3958 - val_loss: 0.3977\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3933 - val_loss: 0.4028\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3905 - val_loss: 0.3704\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3879 - val_loss: 0.3896\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3854 - val_loss: 0.4223\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3837 - val_loss: 0.3803\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3813 - val_loss: 0.4088\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3797 - val_loss: 0.4026\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3779 - val_loss: 0.3792\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3762 - val_loss: 0.3613\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3743 - val_loss: 0.4151\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3735 - val_loss: 0.3659\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3716 - val_loss: 0.4091\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3706 - val_loss: 0.3700\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3690 - val_loss: 0.4020\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3680 - val_loss: 0.3676\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3669 - val_loss: 0.3591\n",
      "162/162 [==============================] - 0s 844us/step - loss: 0.3615\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3614518940448761"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(lr=1e-3))\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(path_+\"my_keras_model.h5\", save_best_only = True)\n",
    "history = model.fit(X_train, y_train, epochs = 20, callbacks = [checkpoint_cb], validation_data = (X_valid, y_valid))\n",
    "mse_test = model.evaluate(X_test, y_test)\n",
    "mse_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=[8]),\n",
    "    keras.layers.Dense(30, activation=\"relu\"),\n",
    "    keras.layers.Dense(1)\n",
    "])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.8562 - val_loss: 1.0100\n",
      "Epoch 2/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.7041 - val_loss: 0.6415\n",
      "Epoch 3/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6287 - val_loss: 0.5932\n",
      "Epoch 4/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5825 - val_loss: 0.5456\n",
      "Epoch 5/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5457 - val_loss: 0.5095\n",
      "Epoch 6/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5155 - val_loss: 0.4821\n",
      "Epoch 7/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4912 - val_loss: 0.4625\n",
      "Epoch 8/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4717 - val_loss: 0.4515\n",
      "Epoch 9/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4560 - val_loss: 0.4453\n",
      "Epoch 10/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4433 - val_loss: 0.4426\n",
      "Epoch 11/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4332 - val_loss: 0.4409\n",
      "Epoch 12/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4250 - val_loss: 0.4423\n",
      "Epoch 13/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4186 - val_loss: 0.4547\n",
      "Epoch 14/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4132 - val_loss: 0.4501\n",
      "Epoch 15/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4091 - val_loss: 0.4421\n",
      "Epoch 16/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4053 - val_loss: 0.4452\n",
      "Epoch 17/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4019 - val_loss: 0.4578\n",
      "Epoch 18/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3991 - val_loss: 0.4641\n",
      "Epoch 19/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3967 - val_loss: 0.4548\n",
      "Epoch 20/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3942 - val_loss: 0.4611\n",
      "Epoch 21/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3921 - val_loss: 0.4747\n",
      "162/162 [==============================] - 0s 1ms/step - loss: 0.3864\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.386422336101532"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(lr=1e-3))\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=10)\n",
    "history = model.fit(X_train, y_train, epochs=100,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[checkpoint_cb, early_stopping_cb])\n",
    "mse_test = model.evaluate(X_test, y_test)\n",
    "mse_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***TensorBoard for Visualization***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "root_logdir = os.path.join(os.curdir, \"my_logs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Nets with Keras.ipynb\r\n",
      "checkpoint\r\n",
      "\u001b[34menviroment_name\u001b[m\u001b[m\r\n",
      "my_keras_model.h5\r\n",
      "my_keras_weights.ckpt.data-00000-of-00001\r\n",
      "my_keras_weights.ckpt.index\r\n",
      "\u001b[34mmy_logs\u001b[m\u001b[m\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_run_logdir():\n",
    "    import time\n",
    "    run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
    "    return os.path.join(root_logdir, run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./my_logs/run_2020_10_13-18_37_07\n",
      "Epoch 1/30\n",
      "  1/363 [..............................] - ETA: 0s - loss: 5.4289WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0012s vs `on_train_batch_end` time: 0.0277s). Check your callbacks.\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 1.4581 - val_loss: 0.7883\n",
      "Epoch 2/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.7368 - val_loss: 0.7306\n",
      "Epoch 3/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6516 - val_loss: 0.6501\n",
      "Epoch 4/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5951 - val_loss: 0.5551\n",
      "Epoch 5/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5536 - val_loss: 0.5025\n",
      "Epoch 6/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5199 - val_loss: 0.4728\n",
      "Epoch 7/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4940 - val_loss: 0.4497\n",
      "Epoch 8/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4730 - val_loss: 0.4359\n",
      "Epoch 9/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4563 - val_loss: 0.4267\n",
      "Epoch 10/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4431 - val_loss: 0.4224\n",
      "Epoch 11/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4333 - val_loss: 0.4265\n",
      "Epoch 12/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4250 - val_loss: 0.4293\n",
      "Epoch 13/30\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4183 - val_loss: 0.4381\n",
      "Epoch 14/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4128 - val_loss: 0.4350\n",
      "Epoch 15/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4081 - val_loss: 0.4364\n",
      "Epoch 16/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4041 - val_loss: 0.4418\n",
      "Epoch 17/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4005 - val_loss: 0.4612\n",
      "Epoch 18/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3975 - val_loss: 0.4649\n",
      "Epoch 19/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3941 - val_loss: 0.4492\n",
      "Epoch 20/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3920 - val_loss: 0.4909\n",
      "Epoch 21/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3894 - val_loss: 0.4866\n",
      "Epoch 22/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3873 - val_loss: 0.4991\n",
      "Epoch 23/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3852 - val_loss: 0.4262\n",
      "Epoch 24/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3832 - val_loss: 0.4452\n",
      "Epoch 25/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3811 - val_loss: 0.4701\n",
      "Epoch 26/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3796 - val_loss: 0.4723\n",
      "Epoch 27/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3781 - val_loss: 0.4295\n",
      "Epoch 28/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3766 - val_loss: 0.4408\n",
      "Epoch 29/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3750 - val_loss: 0.4248\n",
      "Epoch 30/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3736 - val_loss: 0.4406\n",
      "162/162 [==============================] - 0s 922us/step - loss: 0.3728\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.37279757857322693"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_logdir = get_run_logdir()\n",
    "print(run_logdir)\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=[8]),\n",
    "    keras.layers.Dense(30, activation=\"relu\"),\n",
    "    keras.layers.Dense(1)\n",
    "])  \n",
    "\n",
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(lr=1e-3))\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "history = model.fit(X_train, y_train, epochs = 30, validation_data = (X_valid, y_valid), callbacks = [tensorboard_cb])\n",
    "mse_test = model.evaluate(X_test, y_test)\n",
    "mse_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "_repr_pretty_() takes 1 positional argument but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    691\u001b[0m                 \u001b[0mtype_pprinters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_printers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m                 deferred_pprinters=self.deferred_printers)\n\u001b[0;32m--> 693\u001b[0;31m             \u001b[0mprinter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpretty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    694\u001b[0m             \u001b[0mprinter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/IPython/lib/pretty.py\u001b[0m in \u001b[0;36mpretty\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    377\u001b[0m                             \u001b[0mmeth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_repr_pretty_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m                                 \u001b[0;32mreturn\u001b[0m \u001b[0mmeth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcycle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_default_pprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcycle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: _repr_pretty_() takes 1 positional argument but 3 were given"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "_repr_pretty_() takes 1 positional argument but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    691\u001b[0m                 \u001b[0mtype_pprinters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_printers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m                 deferred_pprinters=self.deferred_printers)\n\u001b[0;32m--> 693\u001b[0;31m             \u001b[0mprinter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpretty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    694\u001b[0m             \u001b[0mprinter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/IPython/lib/pretty.py\u001b[0m in \u001b[0;36mpretty\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    377\u001b[0m                             \u001b[0mmeth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_repr_pretty_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m                                 \u001b[0;32mreturn\u001b[0m \u001b[0mmeth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcycle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_default_pprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcycle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: _repr_pretty_() takes 1 positional argument but 3 were given"
     ]
    }
   ],
   "source": [
    "%tensorboard --logdir=./my_logs --port=6006"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***Fine-tuning Hyperparameters***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_model(n_hidden=1, n_neurons=30, learning_rate=3e-3, input_shape=[8]):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.InputLayer(input_shape=input_shape))\n",
    "    for layer in range(n_hidden):\n",
    "        model.add(keras.layers.Dense(n_neurons, activation=\"relu\"))\n",
    "    model.add(keras.layers.Dense(1))\n",
    "    optimizer = keras.optimizers.SGD(lr=learning_rate)\n",
    "    model.compile(loss=\"mse\", optimizer=optimizer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "keras_reg = keras.wrappers.scikit_learn.KerasRegressor(build_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "earlystopping_cb = keras.callbacks.EarlyStopping(patience = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 1.0896 - val_loss: 20.7721\n",
      "Epoch 2/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.7606 - val_loss: 5.0266\n",
      "Epoch 3/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5456 - val_loss: 0.5490\n",
      "Epoch 4/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4732 - val_loss: 0.4529\n",
      "Epoch 5/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4503 - val_loss: 0.4188\n",
      "Epoch 6/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4338 - val_loss: 0.4129\n",
      "Epoch 7/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4241 - val_loss: 0.4004\n",
      "Epoch 8/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4168 - val_loss: 0.3944\n",
      "Epoch 9/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4108 - val_loss: 0.3961\n",
      "Epoch 10/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4060 - val_loss: 0.4071\n",
      "Epoch 11/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4021 - val_loss: 0.3855\n",
      "Epoch 12/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3984 - val_loss: 0.4136\n",
      "Epoch 13/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3951 - val_loss: 0.3997\n",
      "Epoch 14/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3921 - val_loss: 0.3818\n",
      "Epoch 15/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3894 - val_loss: 0.3829\n",
      "Epoch 16/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3869 - val_loss: 0.3739\n",
      "Epoch 17/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3848 - val_loss: 0.4022\n",
      "Epoch 18/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3829 - val_loss: 0.3873\n",
      "Epoch 19/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3807 - val_loss: 0.3768\n",
      "Epoch 20/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3791 - val_loss: 0.4191\n",
      "Epoch 21/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3774 - val_loss: 0.3927\n",
      "Epoch 22/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3756 - val_loss: 0.4237\n",
      "Epoch 23/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3742 - val_loss: 0.3523\n",
      "Epoch 24/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3725 - val_loss: 0.3842\n",
      "Epoch 25/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3710 - val_loss: 0.4162\n",
      "Epoch 26/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3700 - val_loss: 0.3980\n",
      "Epoch 27/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3691 - val_loss: 0.3474\n",
      "Epoch 28/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3677 - val_loss: 0.3920\n",
      "Epoch 29/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3670 - val_loss: 0.3566\n",
      "Epoch 30/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3653 - val_loss: 0.4191\n",
      "Epoch 31/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3647 - val_loss: 0.3721\n",
      "Epoch 32/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3633 - val_loss: 0.3948\n",
      "Epoch 33/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3632 - val_loss: 0.3423\n",
      "Epoch 34/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3617 - val_loss: 0.3453\n",
      "Epoch 35/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3610 - val_loss: 0.4068\n",
      "Epoch 36/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3608 - val_loss: 0.3417\n",
      "Epoch 37/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3596 - val_loss: 0.3787\n",
      "Epoch 38/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3589 - val_loss: 0.3379\n",
      "Epoch 39/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3582 - val_loss: 0.3419\n",
      "Epoch 40/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3572 - val_loss: 0.3705\n",
      "Epoch 41/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3570 - val_loss: 0.3659\n",
      "Epoch 42/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3563 - val_loss: 0.3803\n",
      "Epoch 43/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3552 - val_loss: 0.3765\n",
      "Epoch 44/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3548 - val_loss: 0.3814\n",
      "Epoch 45/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3543 - val_loss: 0.3326\n",
      "Epoch 46/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3532 - val_loss: 0.3385\n",
      "Epoch 47/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3527 - val_loss: 0.3655\n",
      "Epoch 48/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3521 - val_loss: 0.3579\n",
      "Epoch 49/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3525 - val_loss: 0.3360\n",
      "Epoch 50/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3510 - val_loss: 0.3318\n",
      "Epoch 51/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3504 - val_loss: 0.3562\n",
      "Epoch 52/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3502 - val_loss: 0.3520\n",
      "Epoch 53/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3496 - val_loss: 0.4579\n",
      "Epoch 54/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3497 - val_loss: 0.3808\n",
      "Epoch 55/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3490 - val_loss: 0.3539\n",
      "Epoch 56/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3485 - val_loss: 0.3723\n",
      "Epoch 57/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3479 - val_loss: 0.3336\n",
      "Epoch 58/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3469 - val_loss: 0.4011\n",
      "Epoch 59/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3475 - val_loss: 0.3264\n",
      "Epoch 60/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3465 - val_loss: 0.3271\n",
      "Epoch 61/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3452 - val_loss: 0.3346\n",
      "Epoch 62/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3453 - val_loss: 0.3493\n",
      "Epoch 63/100\n",
      "363/363 [==============================] - 0s 999us/step - loss: 0.3444 - val_loss: 0.3402\n",
      "Epoch 64/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3450 - val_loss: 0.3275\n",
      "Epoch 65/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3437 - val_loss: 0.3296\n",
      "Epoch 66/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3431 - val_loss: 0.3307\n",
      "Epoch 67/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3428 - val_loss: 0.3252\n",
      "Epoch 68/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3423 - val_loss: 0.3242\n",
      "Epoch 69/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3419 - val_loss: 0.3254\n",
      "Epoch 70/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3413 - val_loss: 0.3672\n",
      "Epoch 71/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3414 - val_loss: 0.3375\n",
      "Epoch 72/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3405 - val_loss: 0.3271\n",
      "Epoch 73/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3399 - val_loss: 0.3242\n",
      "Epoch 74/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3402 - val_loss: 0.3665\n",
      "Epoch 75/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3397 - val_loss: 0.3283\n",
      "Epoch 76/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3395 - val_loss: 0.3240\n",
      "Epoch 77/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3383 - val_loss: 0.3381\n",
      "Epoch 78/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3384 - val_loss: 0.3356\n",
      "Epoch 79/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3383 - val_loss: 0.3224\n",
      "Epoch 80/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3376 - val_loss: 0.3595\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3383 - val_loss: 0.3432\n",
      "Epoch 82/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3371 - val_loss: 0.3211\n",
      "Epoch 83/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3367 - val_loss: 0.3342\n",
      "Epoch 84/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3362 - val_loss: 0.4136\n",
      "Epoch 85/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3369 - val_loss: 0.3285\n",
      "Epoch 86/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3359 - val_loss: 0.3440\n",
      "Epoch 87/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3357 - val_loss: 0.3733\n",
      "Epoch 88/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3355 - val_loss: 0.3188\n",
      "Epoch 89/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3346 - val_loss: 0.3492\n",
      "Epoch 90/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3348 - val_loss: 0.3175\n",
      "Epoch 91/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3339 - val_loss: 0.3594\n",
      "Epoch 92/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3342 - val_loss: 0.3169\n",
      "Epoch 93/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3333 - val_loss: 0.3607\n",
      "Epoch 94/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3344 - val_loss: 0.5184\n",
      "Epoch 95/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3339 - val_loss: 0.7536\n",
      "Epoch 96/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3370 - val_loss: 0.5075\n",
      "Epoch 97/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3340 - val_loss: 0.8087\n",
      "Epoch 98/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3354 - val_loss: 1.0447\n",
      "Epoch 99/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3346 - val_loss: 1.6881\n",
      "Epoch 100/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3495 - val_loss: 1.9265\n"
     ]
    }
   ],
   "source": [
    "history = keras_reg.fit(X_train, y_train, epochs = 100, \n",
    "                        validation_data = (X_valid, y_valid), \n",
    "                        callbacks = [earlystopping_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 1ms/step - loss: 0.3409\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-0.3408546447753906"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse_test = keras_reg.score(X_test, y_test)\n",
    "mse_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = keras_reg.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.5888452, 1.5484407, 4.1112185], dtype=float32)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import reciprocal\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"n_hidden\": [0, 1, 2, 3],\n",
    "    \"n_neurons\": np.arange(1,100),\n",
    "    \"learning_rate\": [3e-4, 3e-2]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6871 - val_loss: 0.4450\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4781 - val_loss: 0.6098\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4634 - val_loss: 0.4164\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4627 - val_loss: 0.4137\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4560 - val_loss: 0.4341\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4568 - val_loss: 0.4844\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4839 - val_loss: 0.4245\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4483 - val_loss: 0.4555\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4582 - val_loss: 0.4696\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4562 - val_loss: 0.5291\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4544 - val_loss: 0.4475\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4481 - val_loss: 0.4941\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4457 - val_loss: 0.4526\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4451 - val_loss: 0.4543\n",
      "121/121 [==============================] - 0s 914us/step - loss: 0.4407\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.2562 - val_loss: 0.6379\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5638 - val_loss: 0.4676\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4517 - val_loss: 0.4033\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4380 - val_loss: 0.3880\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4330 - val_loss: 0.3969\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4281 - val_loss: 0.3968\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4225 - val_loss: 0.3860\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4198 - val_loss: 0.3771\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4171 - val_loss: 0.3842\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4109 - val_loss: 0.3678\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4031 - val_loss: 0.3769\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3985 - val_loss: 0.3685\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3979 - val_loss: 0.3672\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3950 - val_loss: 0.3608\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3924 - val_loss: 0.3703\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3907 - val_loss: 0.3597\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3905 - val_loss: 0.3559\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3915 - val_loss: 0.3632\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3973 - val_loss: 0.3791\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3910 - val_loss: 0.3568\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3882 - val_loss: 0.3665\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3889 - val_loss: 0.3558\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3905 - val_loss: 0.3769\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3868 - val_loss: 0.3558\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3861 - val_loss: 0.3859\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3827 - val_loss: 0.3679\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3851 - val_loss: 0.3694\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3851 - val_loss: 0.3513\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3841 - val_loss: 0.3621\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3897 - val_loss: 0.3711\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3835 - val_loss: 0.3556\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3854 - val_loss: 0.3556\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3828 - val_loss: 0.3658\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3827 - val_loss: 0.3598\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3825 - val_loss: 0.3516\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3831 - val_loss: 0.3529\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3854 - val_loss: 0.3550\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3825 - val_loss: 0.4079\n",
      "121/121 [==============================] - 0s 962us/step - loss: 0.4620\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7045 - val_loss: 0.4369\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4669 - val_loss: 0.4056\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4658 - val_loss: 0.4058\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4544 - val_loss: 0.3999\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4578 - val_loss: 0.4127\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4500 - val_loss: 0.4076\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4569 - val_loss: 0.3978\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4432 - val_loss: 0.3982\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4406 - val_loss: 0.4021\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4830 - val_loss: 0.3874\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4318 - val_loss: 0.3871\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4246 - val_loss: 0.3829\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4271 - val_loss: 0.3791\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4197 - val_loss: 0.3888\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4191 - val_loss: 0.3750\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4626 - val_loss: 0.3869\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4231 - val_loss: 0.3818\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4163 - val_loss: 0.3817\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4163 - val_loss: 0.3701\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4154 - val_loss: 0.3947\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4185 - val_loss: 0.3758\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4160 - val_loss: 0.3704\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4147 - val_loss: 0.3730\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4141 - val_loss: 0.3707\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4142 - val_loss: 0.3680\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4136 - val_loss: 0.3799\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4137 - val_loss: 0.3738\n",
      "Epoch 28/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4134 - val_loss: 0.3662\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4135 - val_loss: 0.3668\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4162 - val_loss: 0.3805\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4215 - val_loss: 0.3728\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4128 - val_loss: 0.3672\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4140 - val_loss: 0.3718\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4135 - val_loss: 0.3762\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4142 - val_loss: 0.3751\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4170 - val_loss: 0.3685\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4119 - val_loss: 0.3794\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4148 - val_loss: 0.3986\n",
      "121/121 [==============================] - 0s 841us/step - loss: 0.4149\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6596 - val_loss: 50.5061\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8377 - val_loss: 0.4243\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4278 - val_loss: 0.3767\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3870 - val_loss: 0.3512\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3796 - val_loss: 0.3515\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3670 - val_loss: 0.3636\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3647 - val_loss: 0.3431\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3585 - val_loss: 0.3433\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3872 - val_loss: 0.3622\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3705 - val_loss: 0.3396\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3560 - val_loss: 0.3533\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3531 - val_loss: 0.3620\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3557 - val_loss: 0.3564\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3465 - val_loss: 0.3539\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3413 - val_loss: 0.5403\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3401 - val_loss: 0.3321\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3366 - val_loss: 0.3395\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3339 - val_loss: 0.3486\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3323 - val_loss: 0.3556\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3338 - val_loss: 0.3522\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3320 - val_loss: 0.3430\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3269 - val_loss: 0.4417\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3252 - val_loss: 0.3259\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3260 - val_loss: 0.3284\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3210 - val_loss: 0.3560\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3202 - val_loss: 0.3244\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3200 - val_loss: 0.3467\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3286 - val_loss: 0.3478\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3213 - val_loss: 0.3507\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3402 - val_loss: 0.3210\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3212 - val_loss: 0.3094\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3212 - val_loss: 0.3133\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3171 - val_loss: 0.3273\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3147 - val_loss: 0.3494\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3130 - val_loss: 0.3300\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3124 - val_loss: 0.3382\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3135 - val_loss: 0.3105\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3119 - val_loss: 0.3795\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3143 - val_loss: 0.3114\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3104 - val_loss: 0.3079\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3112 - val_loss: 0.3156\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3092 - val_loss: 0.3187\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3132 - val_loss: 0.3107\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3102 - val_loss: 0.3687\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3162 - val_loss: 0.3007\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3101 - val_loss: 0.3093\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3104 - val_loss: 0.3065\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3152 - val_loss: 0.3184\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3085 - val_loss: 0.3136\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3075 - val_loss: 0.3320\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3080 - val_loss: 0.5250\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3083 - val_loss: 0.9963\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3139 - val_loss: 0.2986\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3063 - val_loss: 0.3170\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3049 - val_loss: 0.3058\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3049 - val_loss: 0.3114\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3048 - val_loss: 0.4135\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3103 - val_loss: 0.3058\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3066 - val_loss: 0.3025\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3033 - val_loss: 0.3111\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3078 - val_loss: 0.3357\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3043 - val_loss: 0.4205\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3056 - val_loss: 0.3080\n",
      "121/121 [==============================] - 0s 826us/step - loss: 0.3454\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6474 - val_loss: 0.5290\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4209 - val_loss: 0.8622\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3978 - val_loss: 2.0581\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3965 - val_loss: 0.4981\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3796 - val_loss: 0.3825\n",
      "Epoch 6/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3716 - val_loss: 0.6705\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3717 - val_loss: 0.7766\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3647 - val_loss: 0.5780\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3626 - val_loss: 0.4689\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3591 - val_loss: 0.5263\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3574 - val_loss: 0.4438\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3550 - val_loss: 0.5500\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3535 - val_loss: 0.5119\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3618 - val_loss: 0.3589\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3545 - val_loss: 0.4432\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3497 - val_loss: 0.5433\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3505 - val_loss: 0.8415\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3489 - val_loss: 0.6445\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3475 - val_loss: 0.7840\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3437 - val_loss: 0.7675\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3454 - val_loss: 0.6264\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3438 - val_loss: 0.3781\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3415 - val_loss: 0.3452\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3416 - val_loss: 0.3461\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3414 - val_loss: 0.3676\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3417 - val_loss: 0.3797\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3381 - val_loss: 0.3316\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3397 - val_loss: 3.1735\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3391 - val_loss: 0.4026\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3384 - val_loss: 0.5232\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3354 - val_loss: 0.3245\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3341 - val_loss: 0.6444\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3342 - val_loss: 0.3654\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3328 - val_loss: 2.1410\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3349 - val_loss: 0.4992\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3353 - val_loss: 0.6515\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3312 - val_loss: 0.3276\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3305 - val_loss: 0.3511\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3300 - val_loss: 0.8775\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3277 - val_loss: 0.3257\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3266 - val_loss: 0.4881\n",
      "121/121 [==============================] - 0s 806us/step - loss: 0.3643\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.8348 - val_loss: 5.5345\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4582 - val_loss: 3.4756\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4193 - val_loss: 2.0922\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4210 - val_loss: 0.4023\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3998 - val_loss: 0.3624\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3871 - val_loss: 0.3637\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3829 - val_loss: 0.3532\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3777 - val_loss: 0.3629\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3726 - val_loss: 0.3664\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3687 - val_loss: 0.3546\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3727 - val_loss: 0.3674\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3746 - val_loss: 0.3958\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3638 - val_loss: 0.3579\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3599 - val_loss: 0.3699\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3557 - val_loss: 0.3517\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3526 - val_loss: 0.3949\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3552 - val_loss: 0.3390\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3574 - val_loss: 0.3608\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3498 - val_loss: 0.3580\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3472 - val_loss: 0.3558\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3568 - val_loss: 0.3502\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3516 - val_loss: 0.3267\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3451 - val_loss: 0.3356\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3429 - val_loss: 0.3386\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3454 - val_loss: 0.3198\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3408 - val_loss: 0.3241\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3406 - val_loss: 0.3520\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3381 - val_loss: 0.3224\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3439 - val_loss: 0.3323\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3364 - val_loss: 0.3673\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3339 - val_loss: 0.3356\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3320 - val_loss: 0.3361\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3327 - val_loss: 0.3655\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3277 - val_loss: 0.3476\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3250 - val_loss: 0.3296\n",
      "121/121 [==============================] - 0s 808us/step - loss: 0.3335\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.8020 - val_loss: 0.4658\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4527 - val_loss: 0.4076\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4074 - val_loss: 0.3787\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3951 - val_loss: 0.3658\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3854 - val_loss: 0.3639\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3811 - val_loss: 0.3641\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3798 - val_loss: 0.3610\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3744 - val_loss: 0.3573\n",
      "Epoch 9/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3726 - val_loss: 0.3690\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3733 - val_loss: 0.3498\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3723 - val_loss: 0.3606\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3698 - val_loss: 0.3752\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3676 - val_loss: 0.3534\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3679 - val_loss: 0.3476\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3665 - val_loss: 0.3483\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3659 - val_loss: 0.3485\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3643 - val_loss: 0.3424\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3639 - val_loss: 0.3487\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3619 - val_loss: 0.3429\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3615 - val_loss: 0.3367\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3606 - val_loss: 0.3371\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3593 - val_loss: 0.3495\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3575 - val_loss: 0.3373\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3585 - val_loss: 0.3498\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3557 - val_loss: 0.3638\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3542 - val_loss: 0.3447\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3541 - val_loss: 0.3385\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3527 - val_loss: 0.3318\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3509 - val_loss: 0.3281\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3499 - val_loss: 0.3306\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3506 - val_loss: 0.3277\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3510 - val_loss: 0.3282\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3488 - val_loss: 0.3309\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3478 - val_loss: 0.3312\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3473 - val_loss: 0.3358\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3494 - val_loss: 0.3364\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3478 - val_loss: 0.3256\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3473 - val_loss: 0.3385\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3468 - val_loss: 0.3403\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3484 - val_loss: 0.3253\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3456 - val_loss: 0.3383\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3480 - val_loss: 0.3348\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3483 - val_loss: 0.3284\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3448 - val_loss: 0.3263\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3468 - val_loss: 0.3266\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3448 - val_loss: 0.3310\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3459 - val_loss: 0.3255\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3442 - val_loss: 0.3251\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3427 - val_loss: 0.3224\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3436 - val_loss: 0.3259\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3432 - val_loss: 0.3996\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3443 - val_loss: 0.3240\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3445 - val_loss: 0.3193\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3420 - val_loss: 0.3452\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3409 - val_loss: 0.3278\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3428 - val_loss: 0.3230\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3422 - val_loss: 0.3236\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3409 - val_loss: 0.3280\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3402 - val_loss: 0.3204\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3405 - val_loss: 0.3293\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3405 - val_loss: 0.3292\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3400 - val_loss: 0.3282\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3402 - val_loss: 0.3314\n",
      "121/121 [==============================] - 0s 814us/step - loss: 0.3672\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6506 - val_loss: 1.2181\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4481 - val_loss: 1.2751\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4257 - val_loss: 1.1466\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4177 - val_loss: 1.1193\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4134 - val_loss: 1.2603\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4087 - val_loss: 1.5309\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4040 - val_loss: 1.1535\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4021 - val_loss: 1.3338\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3990 - val_loss: 0.9806\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3967 - val_loss: 0.8123\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3931 - val_loss: 0.6065\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3883 - val_loss: 0.7733\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3885 - val_loss: 0.7487\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3879 - val_loss: 0.5335\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3857 - val_loss: 0.5380\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3819 - val_loss: 0.5950\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3828 - val_loss: 0.5044\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3819 - val_loss: 0.5008\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3800 - val_loss: 0.5375\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3785 - val_loss: 0.4722\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3778 - val_loss: 0.5042\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3791 - val_loss: 0.4511\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3763 - val_loss: 0.4671\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3779 - val_loss: 0.4245\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3739 - val_loss: 0.4442\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3728 - val_loss: 0.4277\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3730 - val_loss: 0.4020\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3710 - val_loss: 0.3955\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3716 - val_loss: 0.4076\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3727 - val_loss: 0.4273\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3685 - val_loss: 0.3767\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3674 - val_loss: 0.3769\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3672 - val_loss: 0.3879\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3648 - val_loss: 0.3933\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3645 - val_loss: 0.3856\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3675 - val_loss: 0.3801\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3660 - val_loss: 0.3806\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3654 - val_loss: 0.4805\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3660 - val_loss: 0.4034\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3630 - val_loss: 0.3896\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3633 - val_loss: 0.3895\n",
      "121/121 [==============================] - 0s 870us/step - loss: 0.3765\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.8533 - val_loss: 6.9879\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5011 - val_loss: 1.1231\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4369 - val_loss: 0.3860\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4226 - val_loss: 0.3833\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4176 - val_loss: 0.3746\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4070 - val_loss: 0.3765\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4013 - val_loss: 0.3671\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3960 - val_loss: 0.3645\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4846 - val_loss: 0.3806\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3994 - val_loss: 0.3578\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3912 - val_loss: 0.3593\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3866 - val_loss: 0.3518\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3839 - val_loss: 0.3545\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3853 - val_loss: 0.3531\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3768 - val_loss: 0.3500\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3834 - val_loss: 0.3520\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3738 - val_loss: 0.3468\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3692 - val_loss: 0.3571\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3692 - val_loss: 0.3326\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3676 - val_loss: 0.3378\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3670 - val_loss: 0.3300\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3637 - val_loss: 0.3314\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3610 - val_loss: 0.3271\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3599 - val_loss: 0.3332\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3594 - val_loss: 0.3250\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3570 - val_loss: 0.3263\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3557 - val_loss: 0.3283\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3573 - val_loss: 0.3256\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3565 - val_loss: 0.3243\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3562 - val_loss: 0.3364\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3547 - val_loss: 0.3251\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3546 - val_loss: 0.3208\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3547 - val_loss: 0.3288\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3530 - val_loss: 0.3337\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3531 - val_loss: 0.3206\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3519 - val_loss: 0.3220\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3502 - val_loss: 0.3389\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3525 - val_loss: 0.3289\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3527 - val_loss: 0.3259\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3518 - val_loss: 0.3204\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3516 - val_loss: 0.3259\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3514 - val_loss: 0.3241\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3505 - val_loss: 0.3218\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3512 - val_loss: 0.3225\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3510 - val_loss: 0.3371\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3487 - val_loss: 0.3414\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3484 - val_loss: 0.3452\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3665 - val_loss: 0.3303\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3521 - val_loss: 0.3447\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3523 - val_loss: 0.3297\n",
      "121/121 [==============================] - 0s 829us/step - loss: 0.3383\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6510 - val_loss: 9.2404\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4992 - val_loss: 8.7915\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4973 - val_loss: 0.3876\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4028 - val_loss: 0.3643\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3929 - val_loss: 0.3699\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3773 - val_loss: 0.3511\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3752 - val_loss: 0.3528\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3656 - val_loss: 0.3486\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3773 - val_loss: 0.3840\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3671 - val_loss: 0.3410\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3617 - val_loss: 0.3516\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3523 - val_loss: 0.3538\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3457 - val_loss: 0.3405\n",
      "Epoch 14/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3433 - val_loss: 0.3243\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3409 - val_loss: 0.3290\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3394 - val_loss: 0.3272\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3366 - val_loss: 0.3219\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3364 - val_loss: 0.3222\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3364 - val_loss: 0.3198\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3323 - val_loss: 0.3145\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3318 - val_loss: 0.3157\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3307 - val_loss: 0.3286\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3283 - val_loss: 0.3171\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3283 - val_loss: 0.3129\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3227 - val_loss: 0.3333\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3228 - val_loss: 0.3256\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3244 - val_loss: 0.3323\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3243 - val_loss: 0.3048\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3186 - val_loss: 0.3126\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3162 - val_loss: 0.3058\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3229 - val_loss: 0.3010\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3181 - val_loss: 0.2995\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3131 - val_loss: 0.3046\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3121 - val_loss: 0.3002\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3115 - val_loss: 0.3024\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3093 - val_loss: 0.3052\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3104 - val_loss: 0.2919\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3082 - val_loss: 0.3116\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3081 - val_loss: 0.3021\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3087 - val_loss: 0.2933\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3073 - val_loss: 0.2954\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3047 - val_loss: 0.3046\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3068 - val_loss: 0.2880\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3030 - val_loss: 0.2920\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3130 - val_loss: 0.2933\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3042 - val_loss: 0.3048\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3031 - val_loss: 0.2932\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3019 - val_loss: 0.2875\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2992 - val_loss: 0.2824\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2988 - val_loss: 0.2895\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2977 - val_loss: 0.3827\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2978 - val_loss: 0.2880\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2975 - val_loss: 0.2806\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2944 - val_loss: 0.2937\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2939 - val_loss: 0.2896\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2963 - val_loss: 0.2817\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2925 - val_loss: 0.2860\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2950 - val_loss: 0.2932\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2940 - val_loss: 0.2808\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2893 - val_loss: 0.2919\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2918 - val_loss: 0.2987\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2898 - val_loss: 0.2974\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2903 - val_loss: 0.2904\n",
      "121/121 [==============================] - 0s 806us/step - loss: 0.3274\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6625 - val_loss: 0.4223\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4535 - val_loss: 0.8550\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4219 - val_loss: 1.0550\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4126 - val_loss: 0.5541\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4040 - val_loss: 0.3707\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3928 - val_loss: 1.2579\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3902 - val_loss: 1.8041\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3865 - val_loss: 1.5875\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3806 - val_loss: 0.7597\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3786 - val_loss: 0.6891\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3704 - val_loss: 2.3812\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3688 - val_loss: 1.3977\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3661 - val_loss: 1.3603\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3651 - val_loss: 0.4208\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3605 - val_loss: 0.9884\n",
      "121/121 [==============================] - 0s 805us/step - loss: 0.3853\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7657 - val_loss: 54.0762\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4998 - val_loss: 0.6107\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4296 - val_loss: 0.3750\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4077 - val_loss: 0.3659\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3959 - val_loss: 0.3654\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3924 - val_loss: 0.3745\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3833 - val_loss: 0.3592\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3773 - val_loss: 0.3660\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3742 - val_loss: 0.3763\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3722 - val_loss: 0.3636\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3689 - val_loss: 0.3613\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3633 - val_loss: 0.3843\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3584 - val_loss: 0.3722\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3562 - val_loss: 0.3754\n",
      "Epoch 15/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3531 - val_loss: 0.3594\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3493 - val_loss: 0.3746\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3507 - val_loss: 0.3515\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3467 - val_loss: 0.3589\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3462 - val_loss: 0.3550\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3434 - val_loss: 0.3633\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3409 - val_loss: 0.3444\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3401 - val_loss: 0.3246\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3375 - val_loss: 0.3407\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3359 - val_loss: 0.3345\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3352 - val_loss: 0.3116\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3328 - val_loss: 0.3184\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3315 - val_loss: 0.3403\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3303 - val_loss: 0.3153\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3293 - val_loss: 0.3569\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3304 - val_loss: 0.3409\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3282 - val_loss: 0.3145\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3264 - val_loss: 0.3293\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3262 - val_loss: 0.3389\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3246 - val_loss: 0.3209\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3218 - val_loss: 0.3084\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3199 - val_loss: 0.3116\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3214 - val_loss: 0.3471\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3252 - val_loss: 0.5417\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3222 - val_loss: 0.3300\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3197 - val_loss: 0.3088\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3213 - val_loss: 0.3330\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3165 - val_loss: 0.3312\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3147 - val_loss: 0.3042\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3197 - val_loss: 0.3102\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3167 - val_loss: 0.3138\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3139 - val_loss: 0.3164\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3123 - val_loss: 0.3100\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3119 - val_loss: 0.3018\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3094 - val_loss: 0.3287\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3098 - val_loss: 0.3256\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3079 - val_loss: 0.3275\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3078 - val_loss: 0.3094\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3103 - val_loss: 0.3249\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3077 - val_loss: 0.3062\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3062 - val_loss: 0.2964\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3030 - val_loss: 0.3172\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3044 - val_loss: 0.3589\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3051 - val_loss: 0.4164\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3049 - val_loss: 0.6566\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3204 - val_loss: 0.3044\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3379 - val_loss: 12.2510\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4943 - val_loss: 0.3319\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 3.0519 - val_loss: 2.1449\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5490 - val_loss: 0.4363\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4497 - val_loss: 0.5357\n",
      "121/121 [==============================] - 0s 900us/step - loss: 0.5420\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 4.1907 - val_loss: 3.1063\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 2.2752 - val_loss: 2.4552\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.5074 - val_loss: 2.0044\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.1479 - val_loss: 1.5434\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9634 - val_loss: 1.2094\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8586 - val_loss: 0.9879\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7954 - val_loss: 0.8380\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7546 - val_loss: 0.7488\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7261 - val_loss: 0.6998\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7047 - val_loss: 0.6679\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6877 - val_loss: 0.6475\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6734 - val_loss: 0.6328\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6608 - val_loss: 0.6209\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6496 - val_loss: 0.6102\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6393 - val_loss: 0.5997\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6297 - val_loss: 0.5908\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6208 - val_loss: 0.5817\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6124 - val_loss: 0.5731\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6045 - val_loss: 0.5646\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5970 - val_loss: 0.5569\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5898 - val_loss: 0.5491\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5831 - val_loss: 0.5420\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5766 - val_loss: 0.5354\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5704 - val_loss: 0.5293\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5646 - val_loss: 0.5231\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5590 - val_loss: 0.5173\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5536 - val_loss: 0.5121\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5485 - val_loss: 0.5070\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5435 - val_loss: 0.5023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5389 - val_loss: 0.4978\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5344 - val_loss: 0.4935\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5301 - val_loss: 0.4896\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5259 - val_loss: 0.4858\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5219 - val_loss: 0.4824\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5181 - val_loss: 0.4792\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5145 - val_loss: 0.4758\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5109 - val_loss: 0.4730\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5075 - val_loss: 0.4699\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5041 - val_loss: 0.4673\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5009 - val_loss: 0.4650\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4977 - val_loss: 0.4622\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4946 - val_loss: 0.4599\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4916 - val_loss: 0.4574\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4888 - val_loss: 0.4554\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4860 - val_loss: 0.4533\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4834 - val_loss: 0.4512\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4810 - val_loss: 0.4500\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4786 - val_loss: 0.4488\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4763 - val_loss: 0.4471\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4742 - val_loss: 0.4455\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4721 - val_loss: 0.4440\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4702 - val_loss: 0.4434\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4683 - val_loss: 0.4430\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4665 - val_loss: 0.4413\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4647 - val_loss: 0.4411\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4630 - val_loss: 0.4403\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4614 - val_loss: 0.4390\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4599 - val_loss: 0.4391\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4584 - val_loss: 0.4380\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4570 - val_loss: 0.4371\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4556 - val_loss: 0.4372\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4543 - val_loss: 0.4369\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4530 - val_loss: 0.4363\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4518 - val_loss: 0.4366\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4505 - val_loss: 0.4366\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4494 - val_loss: 0.4353\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4482 - val_loss: 0.4354\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4471 - val_loss: 0.4358\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4460 - val_loss: 0.4352\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4449 - val_loss: 0.4343\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4439 - val_loss: 0.4350\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4429 - val_loss: 0.4354\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4420 - val_loss: 0.4347\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4410 - val_loss: 0.4342\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4401 - val_loss: 0.4346\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4392 - val_loss: 0.4337\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4383 - val_loss: 0.4331\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4375 - val_loss: 0.4341\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4366 - val_loss: 0.4347\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4358 - val_loss: 0.4337\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4350 - val_loss: 0.4344\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4342 - val_loss: 0.4354\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4335 - val_loss: 0.4348\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4327 - val_loss: 0.4349\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4320 - val_loss: 0.4341\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4312 - val_loss: 0.4354\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4305 - val_loss: 0.4337\n",
      "121/121 [==============================] - 0s 808us/step - loss: 0.4236\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 4.2504 - val_loss: 2.8341\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.1870 - val_loss: 2.1235\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.4088 - val_loss: 1.9846\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.1046 - val_loss: 1.7719\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9705 - val_loss: 1.4896\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8981 - val_loss: 1.2216\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8507 - val_loss: 1.0069\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8154 - val_loss: 0.8609\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7871 - val_loss: 0.7851\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7633 - val_loss: 0.7692\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7426 - val_loss: 0.8023\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7243 - val_loss: 0.8798\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7080 - val_loss: 0.9906\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6932 - val_loss: 1.1207\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6797 - val_loss: 1.2745\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6672 - val_loss: 1.4429\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6557 - val_loss: 1.6175\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6450 - val_loss: 1.8045\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6350 - val_loss: 2.0017\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6257 - val_loss: 2.1948\n",
      "121/121 [==============================] - 0s 797us/step - loss: 0.6808\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 5.0010 - val_loss: 3.5302\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 1ms/step - loss: 2.4438 - val_loss: 2.5087\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.4335 - val_loss: 1.8495\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0351 - val_loss: 1.3873\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8770 - val_loss: 1.0801\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8095 - val_loss: 0.8914\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7752 - val_loss: 0.7919\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7546 - val_loss: 0.7359\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7398 - val_loss: 0.7127\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7277 - val_loss: 0.6999\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7170 - val_loss: 0.6923\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7073 - val_loss: 0.6855\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6981 - val_loss: 0.6774\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6892 - val_loss: 0.6708\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6808 - val_loss: 0.6627\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6727 - val_loss: 0.6565\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6649 - val_loss: 0.6474\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6573 - val_loss: 0.6387\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6500 - val_loss: 0.6343\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6431 - val_loss: 0.6255\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6361 - val_loss: 0.6176\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6294 - val_loss: 0.6102\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6230 - val_loss: 0.6016\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6168 - val_loss: 0.5944\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6107 - val_loss: 0.5872\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6049 - val_loss: 0.5799\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5991 - val_loss: 0.5760\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5936 - val_loss: 0.5698\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5883 - val_loss: 0.5642\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5831 - val_loss: 0.5578\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5780 - val_loss: 0.5532\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5730 - val_loss: 0.5480\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5683 - val_loss: 0.5435\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5636 - val_loss: 0.5386\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5591 - val_loss: 0.5337\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5547 - val_loss: 0.5272\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5505 - val_loss: 0.5216\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5464 - val_loss: 0.5179\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5423 - val_loss: 0.5135\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5385 - val_loss: 0.5091\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5346 - val_loss: 0.5052\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5310 - val_loss: 0.5010\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5275 - val_loss: 0.4967\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5240 - val_loss: 0.4933\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5206 - val_loss: 0.4898\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5174 - val_loss: 0.4865\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5142 - val_loss: 0.4826\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5111 - val_loss: 0.4795\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5080 - val_loss: 0.4764\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5051 - val_loss: 0.4733\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5022 - val_loss: 0.4704\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4994 - val_loss: 0.4677\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4967 - val_loss: 0.4650\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4941 - val_loss: 0.4625\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4915 - val_loss: 0.4602\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4890 - val_loss: 0.4583\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4866 - val_loss: 0.4558\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4842 - val_loss: 0.4534\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4819 - val_loss: 0.4513\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4796 - val_loss: 0.4491\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4775 - val_loss: 0.4477\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4754 - val_loss: 0.4459\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4733 - val_loss: 0.4444\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4714 - val_loss: 0.4429\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4694 - val_loss: 0.4415\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4675 - val_loss: 0.4404\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4657 - val_loss: 0.4383\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4639 - val_loss: 0.4374\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4622 - val_loss: 0.4363\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4605 - val_loss: 0.4341\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4588 - val_loss: 0.4321\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4573 - val_loss: 0.4305\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4557 - val_loss: 0.4298\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4542 - val_loss: 0.4297\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4527 - val_loss: 0.4294\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4513 - val_loss: 0.4291\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4499 - val_loss: 0.4279\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4486 - val_loss: 0.4267\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4472 - val_loss: 0.4264\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4459 - val_loss: 0.4257\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4447 - val_loss: 0.4243\n",
      "Epoch 82/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4434 - val_loss: 0.4236\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4423 - val_loss: 0.4233\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4411 - val_loss: 0.4229\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4400 - val_loss: 0.4224\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4389 - val_loss: 0.4213\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4378 - val_loss: 0.4219\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4367 - val_loss: 0.4208\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4357 - val_loss: 0.4209\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4347 - val_loss: 0.4204\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4337 - val_loss: 0.4195\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4328 - val_loss: 0.4194\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4319 - val_loss: 0.4193\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4310 - val_loss: 0.4197\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4301 - val_loss: 0.4202\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4292 - val_loss: 0.4200\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4284 - val_loss: 0.4199\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4275 - val_loss: 0.4191\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4267 - val_loss: 0.4185\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4260 - val_loss: 0.4190\n",
      "121/121 [==============================] - 0s 748us/step - loss: 0.4275\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 6.5338 - val_loss: 16.8012\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.7791 - val_loss: 10.7399\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.5823 - val_loss: 6.8711\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.7540 - val_loss: 4.4386\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.1732 - val_loss: 2.9254\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.7609 - val_loss: 1.9896\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.4647 - val_loss: 1.4438\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.2504 - val_loss: 1.1378\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0941 - val_loss: 0.9780\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9790 - val_loss: 0.9033\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8937 - val_loss: 0.8811\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8301 - val_loss: 0.8775\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7823 - val_loss: 0.8992\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7461 - val_loss: 0.9284\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7187 - val_loss: 0.9438\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6975 - val_loss: 0.9669\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6811 - val_loss: 0.9868\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6682 - val_loss: 1.0073\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6579 - val_loss: 1.0244\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6497 - val_loss: 1.0363\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6432 - val_loss: 1.0294\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6375 - val_loss: 1.0361\n",
      "121/121 [==============================] - 0s 696us/step - loss: 0.6365\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 7.1703 - val_loss: 38.6564\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 5.3111 - val_loss: 33.0428\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.0268 - val_loss: 28.4914\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.1254 - val_loss: 24.7262\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.4831 - val_loss: 21.5583\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.0188 - val_loss: 18.8542\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.6795 - val_loss: 16.5176\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.4290 - val_loss: 14.4778\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.2424 - val_loss: 12.6861\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.1023 - val_loss: 11.1061\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9962 - val_loss: 9.7014\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9152 - val_loss: 8.4535\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8529 - val_loss: 7.3421\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8046 - val_loss: 6.3561\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7668 - val_loss: 5.4775\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7368 - val_loss: 4.6975\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7129 - val_loss: 4.0074\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6935 - val_loss: 3.3989\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6777 - val_loss: 2.8644\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6645 - val_loss: 2.4002\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6535 - val_loss: 1.9971\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6440 - val_loss: 1.6543\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6358 - val_loss: 1.3646\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6287 - val_loss: 1.1260\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6223 - val_loss: 0.9332\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6167 - val_loss: 0.7834\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6115 - val_loss: 0.6731\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6068 - val_loss: 0.5999\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6024 - val_loss: 0.5605\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5984 - val_loss: 0.5528\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5946 - val_loss: 0.5741\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5911 - val_loss: 0.6222\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5878 - val_loss: 0.6949\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5846 - val_loss: 0.7902\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5817 - val_loss: 0.9065\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5789 - val_loss: 1.0413\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5762 - val_loss: 1.1939\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5737 - val_loss: 1.3624\n",
      "Epoch 39/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5712 - val_loss: 1.5443\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5689 - val_loss: 1.7408\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 0.5999\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 8.2921 - val_loss: 44.0735\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 6.2340 - val_loss: 29.6115\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 4.7744 - val_loss: 20.1524\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 3.7309 - val_loss: 14.0206\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 2.9764 - val_loss: 9.8647\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 2.4263 - val_loss: 7.1321\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.0222 - val_loss: 5.3141\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.7235 - val_loss: 4.1068\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 1.5011 - val_loss: 3.2474\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 1.3337 - val_loss: 2.6271\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.2070 - val_loss: 2.2306\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.1108 - val_loss: 1.9230\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 1.0366 - val_loss: 1.6955\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.9791 - val_loss: 1.5424\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.9341 - val_loss: 1.4194\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.8985 - val_loss: 1.3482\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.8702 - val_loss: 1.2807\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.8471 - val_loss: 1.2271\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.8281 - val_loss: 1.2064\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.8125 - val_loss: 1.1783\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.7990 - val_loss: 1.1560\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.7874 - val_loss: 1.1416\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.7774 - val_loss: 1.1178\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.7685 - val_loss: 1.1047\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.7604 - val_loss: 1.0931\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.7532 - val_loss: 1.0756\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7464 - val_loss: 1.0884\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7403 - val_loss: 1.0835\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7344 - val_loss: 1.0903\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7290 - val_loss: 1.0851\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7238 - val_loss: 1.0863\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.7188 - val_loss: 1.0910\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7140 - val_loss: 1.0942\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.7095 - val_loss: 1.0989\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7051 - val_loss: 1.1024\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7009 - val_loss: 1.0823\n",
      "121/121 [==============================] - 0s 882us/step - loss: 0.7077\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 3.5164 - val_loss: 8.3174\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 2.0754 - val_loss: 6.3348\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.4318 - val_loss: 4.1068\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.1020 - val_loss: 2.4616\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.9136 - val_loss: 1.4567\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.8006 - val_loss: 0.9979\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7334 - val_loss: 0.7637\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6924 - val_loss: 0.6718\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6664 - val_loss: 0.6385\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6480 - val_loss: 0.6225\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6338 - val_loss: 0.6126\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6220 - val_loss: 0.5999\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6114 - val_loss: 0.5921\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6016 - val_loss: 0.5813\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5925 - val_loss: 0.5707\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5837 - val_loss: 0.5627\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5754 - val_loss: 0.5516\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5672 - val_loss: 0.5438\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5594 - val_loss: 0.5348\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5520 - val_loss: 0.5278\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5448 - val_loss: 0.5182\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5378 - val_loss: 0.5113\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5311 - val_loss: 0.5046\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5246 - val_loss: 0.4995\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5187 - val_loss: 0.4918\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5127 - val_loss: 0.4848\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5069 - val_loss: 0.4794\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5014 - val_loss: 0.4731\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4961 - val_loss: 0.4679\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4911 - val_loss: 0.4631\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4863 - val_loss: 0.4585\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4817 - val_loss: 0.4540\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4773 - val_loss: 0.4497\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4731 - val_loss: 0.4456\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4691 - val_loss: 0.4419\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4653 - val_loss: 0.4382\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4616 - val_loss: 0.4350\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4581 - val_loss: 0.4316\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4547 - val_loss: 0.4286\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4516 - val_loss: 0.4263\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4486 - val_loss: 0.4234\n",
      "Epoch 42/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4457 - val_loss: 0.4209\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4430 - val_loss: 0.4183\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4403 - val_loss: 0.4167\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4379 - val_loss: 0.4141\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4355 - val_loss: 0.4114\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4333 - val_loss: 0.4103\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4311 - val_loss: 0.4087\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4290 - val_loss: 0.4070\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4271 - val_loss: 0.4054\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4251 - val_loss: 0.4030\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4233 - val_loss: 0.4026\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4216 - val_loss: 0.4017\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4199 - val_loss: 0.3994\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4182 - val_loss: 0.3994\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4167 - val_loss: 0.3979\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4152 - val_loss: 0.3964\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4137 - val_loss: 0.3968\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4123 - val_loss: 0.3945\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4109 - val_loss: 0.3925\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4097 - val_loss: 0.3928\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4084 - val_loss: 0.3925\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4072 - val_loss: 0.3905\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4061 - val_loss: 0.3915\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4050 - val_loss: 0.3912\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4039 - val_loss: 0.3886\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4028 - val_loss: 0.3881\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4017 - val_loss: 0.3885\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4007 - val_loss: 0.3875\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3997 - val_loss: 0.3855\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3988 - val_loss: 0.3865\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3978 - val_loss: 0.3866\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3969 - val_loss: 0.3841\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3960 - val_loss: 0.3837\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3951 - val_loss: 0.3836\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3942 - val_loss: 0.3823\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3934 - val_loss: 0.3809\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3925 - val_loss: 0.3821\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3917 - val_loss: 0.3816\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3909 - val_loss: 0.3788\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3902 - val_loss: 0.3807\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3894 - val_loss: 0.3814\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3886 - val_loss: 0.3792\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3879 - val_loss: 0.3798\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3871 - val_loss: 0.3777\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3863 - val_loss: 0.3805\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3858 - val_loss: 0.3763\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3850 - val_loss: 0.3740\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3844 - val_loss: 0.3740\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3837 - val_loss: 0.3754\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3831 - val_loss: 0.3732\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3824 - val_loss: 0.3719\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3818 - val_loss: 0.3722\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3812 - val_loss: 0.3715\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3806 - val_loss: 0.3707\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3799 - val_loss: 0.3706\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3794 - val_loss: 0.3683\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3788 - val_loss: 0.3669\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3782 - val_loss: 0.3716\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3778 - val_loss: 0.3676\n",
      "121/121 [==============================] - 0s 713us/step - loss: 0.3902\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 4.5509 - val_loss: 4.9175\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.7600 - val_loss: 8.2687\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0498 - val_loss: 9.6584\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8771 - val_loss: 9.2094\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8056 - val_loss: 8.2185\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7631 - val_loss: 7.2714\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7344 - val_loss: 6.4290\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7132 - val_loss: 5.6720\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6962 - val_loss: 5.0380\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6817 - val_loss: 4.4949\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6685 - val_loss: 4.0302\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6564 - val_loss: 3.5614\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6452 - val_loss: 3.1901\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6346 - val_loss: 2.8750\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6244 - val_loss: 2.5638\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6147 - val_loss: 2.3176\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6053 - val_loss: 2.0693\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5962 - val_loss: 1.8615\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5875 - val_loss: 1.6681\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5791 - val_loss: 1.4982\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5710 - val_loss: 1.3369\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5632 - val_loss: 1.2146\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5556 - val_loss: 1.0961\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5484 - val_loss: 0.9930\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5414 - val_loss: 0.8995\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5347 - val_loss: 0.8213\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5282 - val_loss: 0.7576\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5219 - val_loss: 0.6945\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5158 - val_loss: 0.6573\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5103 - val_loss: 0.6061\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5047 - val_loss: 0.5645\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4993 - val_loss: 0.5350\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4943 - val_loss: 0.5096\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4894 - val_loss: 0.4924\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4847 - val_loss: 0.4769\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4803 - val_loss: 0.4601\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4760 - val_loss: 0.4518\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4719 - val_loss: 0.4432\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4679 - val_loss: 0.4381\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4642 - val_loss: 0.4344\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4605 - val_loss: 0.4315\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4572 - val_loss: 0.4293\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4538 - val_loss: 0.4285\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4507 - val_loss: 0.4272\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4476 - val_loss: 0.4265\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4448 - val_loss: 0.4275\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4421 - val_loss: 0.4265\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4394 - val_loss: 0.4260\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4369 - val_loss: 0.4247\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4346 - val_loss: 0.4254\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4322 - val_loss: 0.4278\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4301 - val_loss: 0.4252\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4280 - val_loss: 0.4237\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4259 - val_loss: 0.4228\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4240 - val_loss: 0.4206\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4222 - val_loss: 0.4187\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4203 - val_loss: 0.4195\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4188 - val_loss: 0.4144\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4171 - val_loss: 0.4120\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4154 - val_loss: 0.4116\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4140 - val_loss: 0.4063\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4126 - val_loss: 0.4036\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4112 - val_loss: 0.4021\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4099 - val_loss: 0.3986\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4085 - val_loss: 0.3945\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4074 - val_loss: 0.3915\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4063 - val_loss: 0.3907\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4051 - val_loss: 0.3869\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4040 - val_loss: 0.3842\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4029 - val_loss: 0.3831\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4019 - val_loss: 0.3811\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4010 - val_loss: 0.3778\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4000 - val_loss: 0.3758\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3991 - val_loss: 0.3736\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3983 - val_loss: 0.3721\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3974 - val_loss: 0.3705\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3965 - val_loss: 0.3695\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3957 - val_loss: 0.3685\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3950 - val_loss: 0.3678\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3942 - val_loss: 0.3672\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3934 - val_loss: 0.3673\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3928 - val_loss: 0.3676\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3920 - val_loss: 0.3687\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3914 - val_loss: 0.3687\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3907 - val_loss: 0.3693\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3900 - val_loss: 0.3710\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3894 - val_loss: 0.3730\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3887 - val_loss: 0.3746\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3882 - val_loss: 0.3787\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3876 - val_loss: 0.3819\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.3966\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 4.2757 - val_loss: 3.7761\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 2.1020 - val_loss: 2.9904\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.3304 - val_loss: 1.5590\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.9899 - val_loss: 1.0268\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.8288 - val_loss: 0.7969\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7456 - val_loss: 0.7051\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6973 - val_loss: 0.6614\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6669 - val_loss: 0.6443\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6462 - val_loss: 0.6120\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6291 - val_loss: 0.5959\n",
      "Epoch 11/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6144 - val_loss: 0.5799\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6019 - val_loss: 0.5671\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5899 - val_loss: 0.5585\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5788 - val_loss: 0.5498\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5683 - val_loss: 0.5399\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5583 - val_loss: 0.5240\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5489 - val_loss: 0.5172\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5398 - val_loss: 0.5090\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5311 - val_loss: 0.4976\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5231 - val_loss: 0.4913\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5151 - val_loss: 0.4843\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5078 - val_loss: 0.4773\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5007 - val_loss: 0.4748\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4938 - val_loss: 0.4749\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4875 - val_loss: 0.4617\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4815 - val_loss: 0.4578\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4757 - val_loss: 0.4469\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4705 - val_loss: 0.4451\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4653 - val_loss: 0.4419\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4607 - val_loss: 0.4357\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4562 - val_loss: 0.4288\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4521 - val_loss: 0.4303\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4480 - val_loss: 0.4227\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4445 - val_loss: 0.4290\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4410 - val_loss: 0.4212\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4378 - val_loss: 0.4215\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4349 - val_loss: 0.4203\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4321 - val_loss: 0.4186\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4294 - val_loss: 0.4119\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4270 - val_loss: 0.4095\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4245 - val_loss: 0.4244\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4226 - val_loss: 0.4214\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4204 - val_loss: 0.4054\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4186 - val_loss: 0.4136\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4166 - val_loss: 0.4087\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4149 - val_loss: 0.4062\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4132 - val_loss: 0.4018\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4117 - val_loss: 0.4003\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4101 - val_loss: 0.4126\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4087 - val_loss: 0.4120\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4073 - val_loss: 0.4064\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4059 - val_loss: 0.4114\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4047 - val_loss: 0.4005\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4034 - val_loss: 0.3938\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4022 - val_loss: 0.3944\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4010 - val_loss: 0.4008\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3999 - val_loss: 0.4041\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3989 - val_loss: 0.4009\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3978 - val_loss: 0.4022\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3968 - val_loss: 0.3914\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3959 - val_loss: 0.3999\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3948 - val_loss: 0.4123\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3941 - val_loss: 0.3959\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3932 - val_loss: 0.3908\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3923 - val_loss: 0.3859\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3914 - val_loss: 0.3988\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3907 - val_loss: 0.3868\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3899 - val_loss: 0.3954\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3892 - val_loss: 0.3907\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3884 - val_loss: 0.3930\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3876 - val_loss: 0.3867\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3869 - val_loss: 0.3991\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3862 - val_loss: 0.3822\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3857 - val_loss: 0.3826\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3850 - val_loss: 0.3951\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3843 - val_loss: 0.4062\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3837 - val_loss: 0.3894\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3831 - val_loss: 0.3939\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3825 - val_loss: 0.3833\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3818 - val_loss: 0.4032\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3813 - val_loss: 0.3940\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3807 - val_loss: 0.3981\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3802 - val_loss: 0.3944\n",
      "121/121 [==============================] - 0s 887us/step - loss: 0.3768\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6402 - val_loss: 43.1203\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 8/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "121/121 [==============================] - 0s 882us/step - loss: nan\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6646 - val_loss: 0.5222\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4410 - val_loss: 0.7222\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4024 - val_loss: 1.3233\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3947 - val_loss: 0.5551\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3896 - val_loss: 0.4478\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3806 - val_loss: 0.8639\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3817 - val_loss: 0.8716\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3717 - val_loss: 0.5133\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3707 - val_loss: 0.4734\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3673 - val_loss: 0.3355\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3633 - val_loss: 0.4382\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3602 - val_loss: 0.8308\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3581 - val_loss: 0.5560\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3646 - val_loss: 0.3463\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3560 - val_loss: 0.4401\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3553 - val_loss: 0.4325\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3530 - val_loss: 0.4504\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3519 - val_loss: 0.5010\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3511 - val_loss: 0.6545\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3470 - val_loss: 0.3765\n",
      "121/121 [==============================] - 0s 847us/step - loss: 0.3551\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7255 - val_loss: 0.4513\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4396 - val_loss: 1.1545\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4174 - val_loss: 2.0400\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4538 - val_loss: 3.2211\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4474 - val_loss: 0.4510\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4140 - val_loss: 0.3829\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3987 - val_loss: 0.3641\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3889 - val_loss: 0.3696\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3876 - val_loss: 0.3652\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3845 - val_loss: 0.3556\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3785 - val_loss: 0.3655\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3802 - val_loss: 0.3580\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3770 - val_loss: 0.3583\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3741 - val_loss: 0.3733\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3768 - val_loss: 0.3577\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3758 - val_loss: 0.3692\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3784 - val_loss: 0.3579\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3723 - val_loss: 0.3678\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3664 - val_loss: 0.3496\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3635 - val_loss: 0.3556\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3666 - val_loss: 0.3506\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3661 - val_loss: 0.3423\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3591 - val_loss: 0.3472\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3579 - val_loss: 0.3514\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3613 - val_loss: 0.3342\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3590 - val_loss: 0.3399\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3534 - val_loss: 0.3396\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3508 - val_loss: 0.3401\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3540 - val_loss: 0.3343\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3494 - val_loss: 0.3325\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3522 - val_loss: 0.3379\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3489 - val_loss: 0.3292\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3465 - val_loss: 0.3389\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3419 - val_loss: 0.3407\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3423 - val_loss: 0.3318\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3408 - val_loss: 0.3242\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3405 - val_loss: 0.3403\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3405 - val_loss: 0.3289\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3406 - val_loss: 0.3257\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3407 - val_loss: 0.3410\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3437 - val_loss: 0.3236\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3394 - val_loss: 0.4399\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3474 - val_loss: 0.3256\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3432 - val_loss: 0.3307\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3421 - val_loss: 0.3233\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3382 - val_loss: 0.3225\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3390 - val_loss: 0.3198\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3375 - val_loss: 0.3255\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3337 - val_loss: 0.3279\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3348 - val_loss: 0.3258\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3353 - val_loss: 0.3577\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3333 - val_loss: 0.3271\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3328 - val_loss: 0.3533\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3323 - val_loss: 0.3243\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3400 - val_loss: 0.3714\n",
      "Epoch 56/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3327 - val_loss: 0.3191\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3356 - val_loss: 0.3154\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3336 - val_loss: 0.3201\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3289 - val_loss: 0.3186\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3307 - val_loss: 0.3175\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3297 - val_loss: 0.3746\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3315 - val_loss: 0.3111\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3285 - val_loss: 0.3183\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3333 - val_loss: 0.3320\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3296 - val_loss: 0.3941\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3260 - val_loss: 0.3098\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3275 - val_loss: 0.3235\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3238 - val_loss: 0.3207\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3239 - val_loss: 0.3253\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3223 - val_loss: 0.3138\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3237 - val_loss: 0.3092\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3274 - val_loss: 0.3152\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3294 - val_loss: 0.3525\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3255 - val_loss: 0.3171\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3248 - val_loss: 0.3379\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3199 - val_loss: 0.4372\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3254 - val_loss: 0.3233\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3260 - val_loss: 0.3279\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3289 - val_loss: 0.3285\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3224 - val_loss: 0.3155\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3263 - val_loss: 0.3249\n",
      "121/121 [==============================] - 0s 805us/step - loss: 0.3301\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 4.0306 - val_loss: 3.0440\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.1563 - val_loss: 2.5874\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.4074 - val_loss: 2.1507\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0640 - val_loss: 1.6293\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8878 - val_loss: 1.1976\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7897 - val_loss: 0.9470\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7320 - val_loss: 0.7942\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6958 - val_loss: 0.7166\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6719 - val_loss: 0.6766\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6545 - val_loss: 0.6510\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6410 - val_loss: 0.6352\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6299 - val_loss: 0.6223\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6203 - val_loss: 0.6123\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6118 - val_loss: 0.6019\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6039 - val_loss: 0.5918\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5967 - val_loss: 0.5832\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5899 - val_loss: 0.5739\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5834 - val_loss: 0.5666\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5773 - val_loss: 0.5595\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5715 - val_loss: 0.5524\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5659 - val_loss: 0.5449\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5606 - val_loss: 0.5388\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5555 - val_loss: 0.5328\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5506 - val_loss: 0.5276\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5459 - val_loss: 0.5221\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5414 - val_loss: 0.5170\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5372 - val_loss: 0.5125\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5330 - val_loss: 0.5080\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5291 - val_loss: 0.5038\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5254 - val_loss: 0.4998\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5218 - val_loss: 0.4960\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5183 - val_loss: 0.4925\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5150 - val_loss: 0.4892\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5117 - val_loss: 0.4861\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5086 - val_loss: 0.4831\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5056 - val_loss: 0.4799\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5027 - val_loss: 0.4778\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5000 - val_loss: 0.4746\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4973 - val_loss: 0.4723\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4948 - val_loss: 0.4703\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4923 - val_loss: 0.4681\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4900 - val_loss: 0.4659\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4877 - val_loss: 0.4637\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4855 - val_loss: 0.4620\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4834 - val_loss: 0.4599\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4813 - val_loss: 0.4575\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4794 - val_loss: 0.4561\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4775 - val_loss: 0.4550\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4756 - val_loss: 0.4532\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4739 - val_loss: 0.4514\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4722 - val_loss: 0.4501\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4705 - val_loss: 0.4489\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4689 - val_loss: 0.4479\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4673 - val_loss: 0.4469\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4658 - val_loss: 0.4462\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4643 - val_loss: 0.4449\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4629 - val_loss: 0.4438\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4615 - val_loss: 0.4436\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4601 - val_loss: 0.4421\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4588 - val_loss: 0.4406\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4575 - val_loss: 0.4402\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4563 - val_loss: 0.4402\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4550 - val_loss: 0.4390\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4538 - val_loss: 0.4385\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4527 - val_loss: 0.4390\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4515 - val_loss: 0.4372\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4504 - val_loss: 0.4366\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4493 - val_loss: 0.4366\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4482 - val_loss: 0.4359\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4472 - val_loss: 0.4341\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4462 - val_loss: 0.4339\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4452 - val_loss: 0.4336\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4442 - val_loss: 0.4319\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4432 - val_loss: 0.4323\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4423 - val_loss: 0.4328\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4414 - val_loss: 0.4317\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4405 - val_loss: 0.4304\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4395 - val_loss: 0.4313\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4387 - val_loss: 0.4298\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4378 - val_loss: 0.4282\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4370 - val_loss: 0.4293\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4362 - val_loss: 0.4307\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4354 - val_loss: 0.4296\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4346 - val_loss: 0.4294\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4339 - val_loss: 0.4275\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4331 - val_loss: 0.4297\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4324 - val_loss: 0.4277\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4317 - val_loss: 0.4264\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4309 - val_loss: 0.4247\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4302 - val_loss: 0.4256\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4295 - val_loss: 0.4245\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4288 - val_loss: 0.4234\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4281 - val_loss: 0.4233\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4275 - val_loss: 0.4218\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4268 - val_loss: 0.4222\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4262 - val_loss: 0.4222\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4256 - val_loss: 0.4208\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4249 - val_loss: 0.4188\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4243 - val_loss: 0.4223\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4237 - val_loss: 0.4203\n",
      "121/121 [==============================] - 0s 782us/step - loss: 0.4341\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 2.9793 - val_loss: 25.3235\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.8631 - val_loss: 29.8112\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3661 - val_loss: 30.4493\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.1237 - val_loss: 28.8130\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9930 - val_loss: 25.9633\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9151 - val_loss: 22.9213\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8643 - val_loss: 19.9656\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8285 - val_loss: 17.1767\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8016 - val_loss: 14.7429\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7798 - val_loss: 12.5538\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7613 - val_loss: 10.6735\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7451 - val_loss: 8.9970\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7305 - val_loss: 7.6270\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7171 - val_loss: 6.4842\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7046 - val_loss: 5.4795\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6927 - val_loss: 4.6235\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6814 - val_loss: 3.8749\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6707 - val_loss: 3.2402\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6605 - val_loss: 2.6837\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6507 - val_loss: 2.2229\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6414 - val_loss: 1.8300\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6324 - val_loss: 1.5119\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6238 - val_loss: 1.2485\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6155 - val_loss: 1.0422\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6076 - val_loss: 0.8732\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5999 - val_loss: 0.7455\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5925 - val_loss: 0.6536\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5854 - val_loss: 0.5906\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5785 - val_loss: 0.5573\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5720 - val_loss: 0.5411\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5657 - val_loss: 0.5453\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5596 - val_loss: 0.5652\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5537 - val_loss: 0.5997\n",
      "Epoch 34/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5481 - val_loss: 0.6385\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5427 - val_loss: 0.6869\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5375 - val_loss: 0.7504\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5325 - val_loss: 0.8134\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5277 - val_loss: 0.8830\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5231 - val_loss: 0.9462\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5187 - val_loss: 1.0129\n",
      "121/121 [==============================] - 0s 817us/step - loss: 0.5408\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 4.8328 - val_loss: 13.3380\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.8366 - val_loss: 11.2300\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.8664 - val_loss: 8.9264\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3594 - val_loss: 6.8972\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0881 - val_loss: 4.8449\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9350 - val_loss: 3.4627\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8452 - val_loss: 2.5410\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7915 - val_loss: 1.8825\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7574 - val_loss: 1.4518\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7343 - val_loss: 1.1658\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7174 - val_loss: 0.9791\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7042 - val_loss: 0.8601\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6934 - val_loss: 0.7843\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6840 - val_loss: 0.7363\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6754 - val_loss: 0.7023\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6674 - val_loss: 0.6768\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6600 - val_loss: 0.6607\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6528 - val_loss: 0.6489\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6459 - val_loss: 0.6388\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6393 - val_loss: 0.6309\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6329 - val_loss: 0.6239\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6267 - val_loss: 0.6177\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6207 - val_loss: 0.6116\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6148 - val_loss: 0.6056\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6090 - val_loss: 0.5998\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6034 - val_loss: 0.5940\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5979 - val_loss: 0.5888\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5926 - val_loss: 0.5831\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5874 - val_loss: 0.5778\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5824 - val_loss: 0.5724\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5774 - val_loss: 0.5675\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5727 - val_loss: 0.5622\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5679 - val_loss: 0.5572\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5635 - val_loss: 0.5520\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5590 - val_loss: 0.5472\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5547 - val_loss: 0.5420\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5505 - val_loss: 0.5369\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5463 - val_loss: 0.5323\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5423 - val_loss: 0.5279\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5384 - val_loss: 0.5235\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5346 - val_loss: 0.5193\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5310 - val_loss: 0.5151\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5274 - val_loss: 0.5111\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5240 - val_loss: 0.5072\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5205 - val_loss: 0.5036\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5173 - val_loss: 0.4999\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5142 - val_loss: 0.4964\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5111 - val_loss: 0.4930\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5081 - val_loss: 0.4897\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5053 - val_loss: 0.4866\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5024 - val_loss: 0.4835\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4997 - val_loss: 0.4807\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4971 - val_loss: 0.4779\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4945 - val_loss: 0.4755\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4920 - val_loss: 0.4730\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4895 - val_loss: 0.4709\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4872 - val_loss: 0.4681\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4850 - val_loss: 0.4661\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4827 - val_loss: 0.4640\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4805 - val_loss: 0.4612\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4785 - val_loss: 0.4598\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4764 - val_loss: 0.4585\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4745 - val_loss: 0.4564\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4726 - val_loss: 0.4546\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4708 - val_loss: 0.4536\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4690 - val_loss: 0.4526\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4673 - val_loss: 0.4501\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4656 - val_loss: 0.4489\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4640 - val_loss: 0.4485\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4624 - val_loss: 0.4467\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4609 - val_loss: 0.4448\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4594 - val_loss: 0.4441\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4580 - val_loss: 0.4424\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4567 - val_loss: 0.4425\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4554 - val_loss: 0.4427\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4541 - val_loss: 0.4422\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4528 - val_loss: 0.4411\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4516 - val_loss: 0.4395\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4505 - val_loss: 0.4397\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4493 - val_loss: 0.4408\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4483 - val_loss: 0.4402\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4472 - val_loss: 0.4391\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4462 - val_loss: 0.4385\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4452 - val_loss: 0.4384\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4442 - val_loss: 0.4377\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4432 - val_loss: 0.4382\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4423 - val_loss: 0.4379\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4414 - val_loss: 0.4371\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4405 - val_loss: 0.4390\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4397 - val_loss: 0.4376\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4389 - val_loss: 0.4367\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4381 - val_loss: 0.4367\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4373 - val_loss: 0.4363\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4365 - val_loss: 0.4365\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4358 - val_loss: 0.4376\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4351 - val_loss: 0.4373\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4343 - val_loss: 0.4379\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4336 - val_loss: 0.4371\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4330 - val_loss: 0.4371\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4323 - val_loss: 0.4375\n",
      "121/121 [==============================] - 0s 807us/step - loss: 0.4340\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6999 - val_loss: 99.9995\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 5.3255 - val_loss: 915.5272\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.5587 - val_loss: 229.7153\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.0811 - val_loss: 3.0099\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "121/121 [==============================] - 0s 885us/step - loss: nan\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5908 - val_loss: 0.4228\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4385 - val_loss: 0.8704\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3949 - val_loss: 1.5817\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3889 - val_loss: 0.4808\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3776 - val_loss: 0.4562\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3671 - val_loss: 1.0678\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3699 - val_loss: 1.0169\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3596 - val_loss: 0.8966\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3560 - val_loss: 0.6647\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3536 - val_loss: 0.4066\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3490 - val_loss: 0.4025\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3638 - val_loss: 1.1273\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3435 - val_loss: 0.6138\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3463 - val_loss: 0.3300\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3412 - val_loss: 0.6632\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3396 - val_loss: 0.4715\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3358 - val_loss: 1.2481\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3350 - val_loss: 0.5675\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3326 - val_loss: 0.9144\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3272 - val_loss: 0.7729\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3296 - val_loss: 0.9283\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3272 - val_loss: 0.6173\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3235 - val_loss: 0.3187\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3242 - val_loss: 0.5905\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3217 - val_loss: 0.8798\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3249 - val_loss: 0.4943\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3191 - val_loss: 0.3154\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3197 - val_loss: 2.2836\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3219 - val_loss: 1.7786\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3185 - val_loss: 0.6034\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3147 - val_loss: 1.1684\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3148 - val_loss: 0.3022\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3123 - val_loss: 1.1721\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3102 - val_loss: 1.4197\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3139 - val_loss: 0.3064\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3094 - val_loss: 0.4568\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3110 - val_loss: 0.3384\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3092 - val_loss: 0.8206\n",
      "Epoch 39/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3073 - val_loss: 0.3110\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3061 - val_loss: 0.3075\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3079 - val_loss: 1.9604\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3054 - val_loss: 0.2939\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3052 - val_loss: 1.5839\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3059 - val_loss: 0.3175\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3069 - val_loss: 1.9204\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3054 - val_loss: 0.4824\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3027 - val_loss: 0.3182\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3077 - val_loss: 4.3804\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3027 - val_loss: 0.3144\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3035 - val_loss: 1.8224\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2984 - val_loss: 1.9392\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2996 - val_loss: 0.6154\n",
      "121/121 [==============================] - 0s 823us/step - loss: 0.3148\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7747 - val_loss: 43.5744\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4826 - val_loss: 2.4864\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4024 - val_loss: 0.4299\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3944 - val_loss: 2.6521\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4053 - val_loss: 10.7498\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4140 - val_loss: 7.7183\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4431 - val_loss: 2.2718\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3820 - val_loss: 1.6651\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3869 - val_loss: 1.8628\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3625 - val_loss: 0.6700\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3627 - val_loss: 0.5699\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3531 - val_loss: 0.9588\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3510 - val_loss: 0.6619\n",
      "121/121 [==============================] - 0s 822us/step - loss: 0.3381\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Cannot clone object <tensorflow.python.keras.wrappers.scikit_learn.KerasRegressor object at 0x13c7dbcc0>, as the constructor either does not set or modifies parameter n_neurons",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-68-bd4bd0ee9dbd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m history = rnd_search_cv.fit(X_train, y_train, epochs = 100, \n\u001b[1;32m      3\u001b[0m                             \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m                             callbacks = [earlystopping_cb])\n\u001b[0m",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    760\u001b[0m             \u001b[0;31m# of the params are estimators as well.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m             self.best_estimator_ = clone(clone(base_estimator).set_params(\n\u001b[0;32m--> 762\u001b[0;31m                 **self.best_params_))\n\u001b[0m\u001b[1;32m    763\u001b[0m             \u001b[0mrefit_start_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mclone\u001b[0;34m(estimator, safe)\u001b[0m\n\u001b[1;32m     96\u001b[0m             raise RuntimeError('Cannot clone object %s, as the constructor '\n\u001b[1;32m     97\u001b[0m                                \u001b[0;34m'either does not set or modifies parameter %s'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m                                (estimator, name))\n\u001b[0m\u001b[1;32m     99\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnew_object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Cannot clone object <tensorflow.python.keras.wrappers.scikit_learn.KerasRegressor object at 0x13c7dbcc0>, as the constructor either does not set or modifies parameter n_neurons"
     ]
    }
   ],
   "source": [
    "rnd_search_cv = RandomizedSearchCV(keras_reg, params, n_iter = 10, cv = 3)\n",
    "history = rnd_search_cv.fit(X_train, y_train, epochs = 100, \n",
    "                            validation_data = (X_valid, y_valid), \n",
    "                            callbacks = [earlystopping_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 1ms/step - loss: 0.3409\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-0.3408546447753906"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse_test = keras_reg.score(X_test, y_test)\n",
    "mse_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.5888452, 1.5484407, 4.1112185], dtype=float32)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = keras_reg.predict(X_new)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.03, 'n_hidden': 1, 'n_neurons': 34}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.3477271596590678"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'RandomizedSearchCV' object has no attribute 'best_estimator_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-76-059a6ae6c0f6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnd_search_cv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'RandomizedSearchCV' object has no attribute 'best_estimator_'"
     ]
    }
   ],
   "source": [
    "model = rnd_search_cv.best_estimator_.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 1ms/step - loss: 0.3728\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.37279757857322693"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***Exercise***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Question 10***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from keras.datasets.mnist import load_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(X_train_full, y_train_full), (X_test, y_test) = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((55000, 28, 28), (5000, 28, 28), (10000, 28, 28))"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_valid, X_train = X_train_full[:5000] / 255., X_train_full[5000:] / 255.\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
    "X_test = X_test / 255.\n",
    "\n",
    "X_train.shape, X_valid.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_train[1], cmap=\"binary\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x345.6 with 40 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_rows = 4\n",
    "n_cols = 10\n",
    "plt.figure(figsize=(n_cols * 1.2, n_rows * 1.2))\n",
    "for row in range(n_rows):\n",
    "    for col in range(n_cols):\n",
    "        index = n_cols * row + col\n",
    "        plt.subplot(n_rows, n_cols, index + 1)\n",
    "        plt.imshow(X_train[index], cmap=\"binary\", interpolation=\"nearest\")\n",
    "        plt.axis('off')\n",
    "        plt.title(y_train[index], fontsize=12)\n",
    "plt.subplots_adjust(wspace=0.2, hspace=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "K = keras.backend\n",
    "\n",
    "class ExponentialLearningRate(keras.callbacks.Callback):\n",
    "    def __init__(self, factor):\n",
    "        self.factor = factor\n",
    "        self.rates = []\n",
    "        self.losses = []\n",
    "    def on_batch_end(self, batch, logs):\n",
    "        self.rates.append(K.get_value(self.model.optimizer.lr))\n",
    "        self.losses.append(logs[\"loss\"])\n",
    "        K.set_value(self.model.optimizer.lr, self.model.optimizer.lr * self.factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, activation=\"relu\"),\n",
    "    keras.layers.Dense(100, activation=\"relu\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=keras.optimizers.SGD(lr=1e-3),\n",
    "              metrics=[\"accuracy\"])\n",
    "expon_lr = ExponentialLearningRate(factor=1.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1719/1719 [==============================] - 5s 3ms/step - loss: nan - accuracy: 0.6030 - val_loss: nan - val_accuracy: 0.0958\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=1,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[expon_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Loss')"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(expon_lr.rates, expon_lr.losses)\n",
    "plt.gca().set_xscale('log')\n",
    "plt.hlines(min(expon_lr.losses), min(expon_lr.rates), max(expon_lr.rates))\n",
    "plt.axis([min(expon_lr.rates), max(expon_lr.rates), 0, expon_lr.losses[0]])\n",
    "plt.xlabel(\"Learning rate\")\n",
    "plt.ylabel(\"Loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, activation=\"relu\"),\n",
    "    keras.layers.Dense(100, activation=\"relu\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=keras.optimizers.SGD(lr=2e-1),\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./my_mnist_logs/run_001'"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_index = 1 # increment this at every run\n",
    "run_logdir = os.path.join(os.curdir, \"my_mnist_logs\", \"run_{:03d}\".format(run_index))\n",
    "run_logdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "   2/1719 [..............................] - ETA: 1:09 - loss: 0.0031 - accuracy: 0.0625WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0025s vs `on_train_batch_end` time: 0.0790s). Check your callbacks.\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.0255 - accuracy: 0.0990 - val_loss: 0.0725 - val_accuracy: 0.0960\n",
      "Epoch 2/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.0204 - accuracy: 0.0991 - val_loss: 0.0715 - val_accuracy: 0.0958\n",
      "Epoch 3/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.0121 - accuracy: 0.0990 - val_loss: 0.0729 - val_accuracy: 0.0956\n",
      "Epoch 4/100\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.0082 - accuracy: 0.0990 - val_loss: 0.0727 - val_accuracy: 0.0960\n",
      "Epoch 5/100\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.0086 - accuracy: 0.0989 - val_loss: 0.0739 - val_accuracy: 0.0950\n",
      "Epoch 6/100\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.0085 - accuracy: 0.0990 - val_loss: 0.0757 - val_accuracy: 0.0954\n",
      "Epoch 7/100\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.0107 - accuracy: 0.0990 - val_loss: 0.0784 - val_accuracy: 0.0966\n",
      "Epoch 8/100\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.0056 - accuracy: 0.0990 - val_loss: 0.0817 - val_accuracy: 0.0968\n",
      "Epoch 9/100\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.0025 - accuracy: 0.0991 - val_loss: 0.0851 - val_accuracy: 0.0956\n",
      "Epoch 10/100\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.0018 - accuracy: 0.0990 - val_loss: 0.0763 - val_accuracy: 0.0964\n",
      "Epoch 11/100\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 5.4814e-04 - accuracy: 0.0990 - val_loss: 0.0778 - val_accuracy: 0.0958\n",
      "Epoch 12/100\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 2.0680e-04 - accuracy: 0.0990 - val_loss: 0.0775 - val_accuracy: 0.0958\n",
      "Epoch 13/100\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 1.5493e-04 - accuracy: 0.0990 - val_loss: 0.0789 - val_accuracy: 0.0962\n",
      "Epoch 14/100\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 1.3352e-04 - accuracy: 0.0990 - val_loss: 0.0800 - val_accuracy: 0.0962\n",
      "Epoch 15/100\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 1.1725e-04 - accuracy: 0.0990 - val_loss: 0.0808 - val_accuracy: 0.0960\n",
      "Epoch 16/100\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 1.0599e-04 - accuracy: 0.0990 - val_loss: 0.0817 - val_accuracy: 0.0960\n",
      "Epoch 17/100\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 9.7532e-05 - accuracy: 0.0990 - val_loss: 0.0824 - val_accuracy: 0.0960\n",
      "Epoch 18/100\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 8.9992e-05 - accuracy: 0.0990 - val_loss: 0.0828 - val_accuracy: 0.0960\n",
      "Epoch 19/100\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 8.4325e-05 - accuracy: 0.0990 - val_loss: 0.0830 - val_accuracy: 0.0960\n",
      "Epoch 20/100\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 7.9046e-05 - accuracy: 0.0990 - val_loss: 0.0834 - val_accuracy: 0.0960\n",
      "Epoch 21/100\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 7.4675e-05 - accuracy: 0.0990 - val_loss: 0.0838 - val_accuracy: 0.0960\n",
      "Epoch 22/100\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 7.0669e-05 - accuracy: 0.0990 - val_loss: 0.0843 - val_accuracy: 0.0960\n"
     ]
    }
   ],
   "source": [
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=20)\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_mnist_model.h5\", save_best_only=True)\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=100,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[early_stopping_cb, checkpoint_cb, tensorboard_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0734 - accuracy: 0.0986\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0733974277973175, 0.09860000014305115]"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.models.load_model(\"my_mnist_model.h5\") # rollback to best model\n",
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "_repr_pretty_() takes 1 positional argument but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    691\u001b[0m                 \u001b[0mtype_pprinters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_printers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m                 deferred_pprinters=self.deferred_printers)\n\u001b[0;32m--> 693\u001b[0;31m             \u001b[0mprinter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpretty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    694\u001b[0m             \u001b[0mprinter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/IPython/lib/pretty.py\u001b[0m in \u001b[0;36mpretty\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    377\u001b[0m                             \u001b[0mmeth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_repr_pretty_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m                                 \u001b[0;32mreturn\u001b[0m \u001b[0mmeth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcycle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_default_pprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcycle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: _repr_pretty_() takes 1 positional argument but 3 were given"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "_repr_pretty_() takes 1 positional argument but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    691\u001b[0m                 \u001b[0mtype_pprinters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_printers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m                 deferred_pprinters=self.deferred_printers)\n\u001b[0;32m--> 693\u001b[0;31m             \u001b[0mprinter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpretty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    694\u001b[0m             \u001b[0mprinter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/IPython/lib/pretty.py\u001b[0m in \u001b[0;36mpretty\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    377\u001b[0m                             \u001b[0mmeth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_repr_pretty_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m                                 \u001b[0;32mreturn\u001b[0m \u001b[0mmeth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcycle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_default_pprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcycle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: _repr_pretty_() takes 1 positional argument but 3 were given"
     ]
    }
   ],
   "source": [
    "%tensorboard --logdir=./my_mnist_logs --port=6006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
